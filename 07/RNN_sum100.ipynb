{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Sum 100 - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for reproducable solutions\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 samples (8000 train, 2000 test), numbers from 0 to 9, sequences of length 30\n",
    "samples = 10000\n",
    "seq_length = 30\n",
    "epochs = 60\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(samples, seq_length):\n",
    "    x_ = np.random.random_integers(low=0, high=9, size=(samples, seq_length))\n",
    "    # needs one more dim for keras\n",
    "    x = x_[:, :, np.newaxis]\n",
    "    y = np.sum(x_, axis=1) \n",
    "    y = y[:,np.newaxis]\n",
    "    y = y >= 100\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# get the numbers from boolean labels\n",
    "def y_to_nb(y):\n",
    "    return y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13876/3591819934.py:2: DeprecationWarning: This function is deprecated. Please call randint(0, 9 + 1) instead\n",
      "  x_ = np.random.random_integers(low=0, high=9, size=(samples, seq_length))\n"
     ]
    }
   ],
   "source": [
    "x, y = create_data(samples, seq_length)\n",
    "x_tr, x_test, y_tr, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 30, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 200)               161600    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,801\n",
      "Trainable params: 161,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# 200 lstm cells\n",
    "model.add(LSTM(200, input_shape=(seq_length,1)))\n",
    "# sigmoid is important to use it for binary_crossentropy \n",
    "\n",
    "# TimeDistributed layer would create output at each step\n",
    "# but Recurrent layer would have to return_sequence\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "160/160 [==============================] - 5s 24ms/step - loss: 0.0680 - accuracy: 0.9805 - val_loss: 0.0414 - val_accuracy: 0.9870\n",
      "Epoch 2/60\n",
      "160/160 [==============================] - 4s 23ms/step - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0352 - val_accuracy: 0.9865\n",
      "Epoch 3/60\n",
      "142/160 [=========================>....] - ETA: 0s - loss: 0.0342 - accuracy: 0.9873"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/mnt/data/projects/venvs/jupyter/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_tr, y_tr, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0162, Accuracy: 99.45%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss: %0.4f, Accuracy: %.2f%%\" % (scores[0], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Data to Torch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr.astype(np.float32, copy=False)\n",
    "tensor_x_tr = torch.Tensor(x_tr)\n",
    "\n",
    "y_tr = y_tr.astype(np.float32, copy=False)\n",
    "tensor_y_tr = torch.Tensor(y_tr)\n",
    "\n",
    "x_test = x_test.astype(np.float32, copy=False)\n",
    "tensor_x_test = torch.Tensor(x_test)\n",
    "\n",
    "y_test = y_test.astype(np.float32, copy=False)\n",
    "tensor_y_test = torch.Tensor(y_test)\n",
    "\n",
    "# create datasets\n",
    "train_data = torch.utils.data.TensorDataset(tensor_x_tr, tensor_y_tr) \n",
    "test_data = torch.utils.data.TensorDataset(tensor_x_test, tensor_y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_data, batch_size=x_test.__len__(), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNN(nn.Module):\n",
    "    # just the layers and other variables\n",
    "    # computation is defined in forward method\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            \n",
    "        # 200 lstm cells\n",
    "        self.num_units = 200\n",
    "        \n",
    "        # one layer, with 200 cells \n",
    "        # data is passed with batch_size as first dim\n",
    "        # easier to handle in forward pass\n",
    "        self.lstm = nn.LSTM(1, self.num_units, batch_first = True)\n",
    "        \n",
    "        # 200 cells map to one output\n",
    "        self.output = nn.Linear(self.num_units, 1)\n",
    "        \n",
    "    # helper method\n",
    "    def init_hidden(self, batch_size):\n",
    "        # initial hidden state is empty -> zeros\n",
    "        return (Variable(torch.zeros(1, batch_size, self.num_units)),\n",
    "                Variable(torch.zeros(1, batch_size, self.num_units)))\n",
    "\n",
    "    # computation is done here\n",
    "    # backward pass (backprop) is calculated automatically\n",
    "    def forward(self, x):\n",
    "        # get batch_size from data\n",
    "        # evaluation of the model done on complete test batch\n",
    "        batch_size = x.size()[0]\n",
    "\n",
    "        # initial hidden state (step = 0)\n",
    "        hidden_0 = self.init_hidden(batch_size)\n",
    "        \n",
    "        # pass input and first hidden state, to lstm\n",
    "        # defined in __init__\n",
    "        lstm_out, last = self.lstm(x, hidden_0)\n",
    "        # lstm_out contains all hidden states (at each time step)\n",
    "        # should be possible to use a dense layer on all steps\n",
    "        # last (tuple) contains hidden and cell state of last step\n",
    "        \n",
    "        # take hidden state at last timestep \n",
    "        # dim order is changed due to batch_first = True\n",
    "        out = self.output(lstm_out[:,-1,:])\n",
    "        # or\n",
    "        #out = self.output(last[0][0,:,:]) \n",
    "        # both are the same\n",
    "        \n",
    "        out = F.sigmoid(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # indicates training\n",
    "    # useful for e.g. dropout\n",
    "    # here not necessary but good practice\n",
    "    model.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        # input has to be a autograd.Variable\n",
    "        # allows automatic differentiation\n",
    "        data, label = Variable(data), Variable(label)\n",
    "        # has to done before each optimizer step \n",
    "        # (each backprop)\n",
    "        # optimizer accumulates the changes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, label)\n",
    "        # calculates the backpropagation started at the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # updates the parameters of the network\n",
    "        # by specified optimizer\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "            \n",
    "def test():\n",
    "    # indicates testing\n",
    "    # useful for e.g. dropout\n",
    "    # here not necessary but good practice\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, label in test_loader:\n",
    "        # volatile true deactivates\n",
    "        # the calculation of gradients in backward pass\n",
    "        # also deactivates all nodes that depend on data \n",
    "        # means whole network doesn't calculate gradients\n",
    "        data, label = Variable(data, volatile=True), Variable(label)\n",
    "        \n",
    "        output = model(data)\n",
    "        test_loss += F.binary_cross_entropy(output, label, \n",
    "                        size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.ge(0.5).float() # to 1.0 if >= 0.5 else 0.0\n",
    "        correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Epochs: 60\n",
      "Train Epoch: 1 [0/8000 (0%)]\tLoss: 0.710394\n",
      "Train Epoch: 1 [500/8000 (6%)]\tLoss: 0.109925\n",
      "Train Epoch: 1 [1000/8000 (12%)]\tLoss: 0.003429\n",
      "Train Epoch: 1 [1500/8000 (19%)]\tLoss: 0.231383\n",
      "Train Epoch: 1 [2000/8000 (25%)]\tLoss: 0.009938\n",
      "Train Epoch: 1 [2500/8000 (31%)]\tLoss: 0.183802\n",
      "Train Epoch: 1 [3000/8000 (38%)]\tLoss: 0.177125\n",
      "Train Epoch: 1 [3500/8000 (44%)]\tLoss: 0.012175\n",
      "Train Epoch: 1 [4000/8000 (50%)]\tLoss: 0.204910\n",
      "Train Epoch: 1 [4500/8000 (56%)]\tLoss: 0.105060\n",
      "Train Epoch: 1 [5000/8000 (62%)]\tLoss: 0.099537\n",
      "Train Epoch: 1 [5500/8000 (69%)]\tLoss: 0.099801\n",
      "Train Epoch: 1 [6000/8000 (75%)]\tLoss: 0.174862\n",
      "Train Epoch: 1 [6500/8000 (81%)]\tLoss: 0.015048\n",
      "Train Epoch: 1 [7000/8000 (88%)]\tLoss: 0.195471\n",
      "Train Epoch: 1 [7500/8000 (94%)]\tLoss: 0.012824\n",
      "\n",
      "Test set: Average loss: 0.0581, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/8000 (0%)]\tLoss: 0.012306\n",
      "Train Epoch: 2 [500/8000 (6%)]\tLoss: 0.014550\n",
      "Train Epoch: 2 [1000/8000 (12%)]\tLoss: 0.097608\n",
      "Train Epoch: 2 [1500/8000 (19%)]\tLoss: 0.014347\n",
      "Train Epoch: 2 [2000/8000 (25%)]\tLoss: 0.012327\n",
      "Train Epoch: 2 [2500/8000 (31%)]\tLoss: 0.102890\n",
      "Train Epoch: 2 [3000/8000 (38%)]\tLoss: 0.277008\n",
      "Train Epoch: 2 [3500/8000 (44%)]\tLoss: 0.094735\n",
      "Train Epoch: 2 [4000/8000 (50%)]\tLoss: 0.182079\n",
      "Train Epoch: 2 [4500/8000 (56%)]\tLoss: 0.010630\n",
      "Train Epoch: 2 [5000/8000 (62%)]\tLoss: 0.206929\n",
      "Train Epoch: 2 [5500/8000 (69%)]\tLoss: 0.015158\n",
      "Train Epoch: 2 [6000/8000 (75%)]\tLoss: 0.016448\n",
      "Train Epoch: 2 [6500/8000 (81%)]\tLoss: 0.009444\n",
      "Train Epoch: 2 [7000/8000 (88%)]\tLoss: 0.105598\n",
      "Train Epoch: 2 [7500/8000 (94%)]\tLoss: 0.098642\n",
      "\n",
      "Test set: Average loss: 0.0579, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/8000 (0%)]\tLoss: 0.010233\n",
      "Train Epoch: 3 [500/8000 (6%)]\tLoss: 0.182370\n",
      "Train Epoch: 3 [1000/8000 (12%)]\tLoss: 0.015572\n",
      "Train Epoch: 3 [1500/8000 (19%)]\tLoss: 0.014672\n",
      "Train Epoch: 3 [2000/8000 (25%)]\tLoss: 0.013362\n",
      "Train Epoch: 3 [2500/8000 (31%)]\tLoss: 0.188242\n",
      "Train Epoch: 3 [3000/8000 (38%)]\tLoss: 0.193375\n",
      "Train Epoch: 3 [3500/8000 (44%)]\tLoss: 0.011071\n",
      "Train Epoch: 3 [4000/8000 (50%)]\tLoss: 0.009776\n",
      "Train Epoch: 3 [4500/8000 (56%)]\tLoss: 0.101058\n",
      "Train Epoch: 3 [5000/8000 (62%)]\tLoss: 0.099106\n",
      "Train Epoch: 3 [5500/8000 (69%)]\tLoss: 0.012651\n",
      "Train Epoch: 3 [6000/8000 (75%)]\tLoss: 0.096681\n",
      "Train Epoch: 3 [6500/8000 (81%)]\tLoss: 0.102362\n",
      "Train Epoch: 3 [7000/8000 (88%)]\tLoss: 0.020156\n",
      "Train Epoch: 3 [7500/8000 (94%)]\tLoss: 0.098833\n",
      "\n",
      "Test set: Average loss: 0.0584, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/8000 (0%)]\tLoss: 0.089738\n",
      "Train Epoch: 4 [500/8000 (6%)]\tLoss: 0.010964\n",
      "Train Epoch: 4 [1000/8000 (12%)]\tLoss: 0.176758\n",
      "Train Epoch: 4 [1500/8000 (19%)]\tLoss: 0.098255\n",
      "Train Epoch: 4 [2000/8000 (25%)]\tLoss: 0.008075\n",
      "Train Epoch: 4 [2500/8000 (31%)]\tLoss: 0.107322\n",
      "Train Epoch: 4 [3000/8000 (38%)]\tLoss: 0.097734\n",
      "Train Epoch: 4 [3500/8000 (44%)]\tLoss: 0.182683\n",
      "Train Epoch: 4 [4000/8000 (50%)]\tLoss: 0.171318\n",
      "Train Epoch: 4 [4500/8000 (56%)]\tLoss: 0.012804\n",
      "Train Epoch: 4 [5000/8000 (62%)]\tLoss: 0.174103\n",
      "Train Epoch: 4 [5500/8000 (69%)]\tLoss: 0.099131\n",
      "Train Epoch: 4 [6000/8000 (75%)]\tLoss: 0.021876\n",
      "Train Epoch: 4 [6500/8000 (81%)]\tLoss: 0.101961\n",
      "Train Epoch: 4 [7000/8000 (88%)]\tLoss: 0.006268\n",
      "Train Epoch: 4 [7500/8000 (94%)]\tLoss: 0.008506\n",
      "\n",
      "Test set: Average loss: 0.0612, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/8000 (0%)]\tLoss: 0.022781\n",
      "Train Epoch: 5 [500/8000 (6%)]\tLoss: 0.171625\n",
      "Train Epoch: 5 [1000/8000 (12%)]\tLoss: 0.014337\n",
      "Train Epoch: 5 [1500/8000 (19%)]\tLoss: 0.006263\n",
      "Train Epoch: 5 [2000/8000 (25%)]\tLoss: 0.011575\n",
      "Train Epoch: 5 [2500/8000 (31%)]\tLoss: 0.101776\n",
      "Train Epoch: 5 [3000/8000 (38%)]\tLoss: 0.017575\n",
      "Train Epoch: 5 [3500/8000 (44%)]\tLoss: 0.011227\n",
      "Train Epoch: 5 [4000/8000 (50%)]\tLoss: 0.101365\n",
      "Train Epoch: 5 [4500/8000 (56%)]\tLoss: 0.024864\n",
      "Train Epoch: 5 [5000/8000 (62%)]\tLoss: 0.017485\n",
      "Train Epoch: 5 [5500/8000 (69%)]\tLoss: 0.009043\n",
      "Train Epoch: 5 [6000/8000 (75%)]\tLoss: 0.010348\n",
      "Train Epoch: 5 [6500/8000 (81%)]\tLoss: 0.012161\n",
      "Train Epoch: 5 [7000/8000 (88%)]\tLoss: 0.008327\n",
      "Train Epoch: 5 [7500/8000 (94%)]\tLoss: 0.005512\n",
      "\n",
      "Test set: Average loss: 0.0572, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/8000 (0%)]\tLoss: 0.109745\n",
      "Train Epoch: 6 [500/8000 (6%)]\tLoss: 0.020661\n",
      "Train Epoch: 6 [1000/8000 (12%)]\tLoss: 0.083447\n",
      "Train Epoch: 6 [1500/8000 (19%)]\tLoss: 0.009057\n",
      "Train Epoch: 6 [2000/8000 (25%)]\tLoss: 0.176295\n",
      "Train Epoch: 6 [2500/8000 (31%)]\tLoss: 0.107888\n",
      "Train Epoch: 6 [3000/8000 (38%)]\tLoss: 0.033361\n",
      "Train Epoch: 6 [3500/8000 (44%)]\tLoss: 0.281043\n",
      "Train Epoch: 6 [4000/8000 (50%)]\tLoss: 0.020456\n",
      "Train Epoch: 6 [4500/8000 (56%)]\tLoss: 0.076279\n",
      "Train Epoch: 6 [5000/8000 (62%)]\tLoss: 0.005342\n",
      "Train Epoch: 6 [5500/8000 (69%)]\tLoss: 0.006492\n",
      "Train Epoch: 6 [6000/8000 (75%)]\tLoss: 0.017616\n",
      "Train Epoch: 6 [6500/8000 (81%)]\tLoss: 0.006218\n",
      "Train Epoch: 6 [7000/8000 (88%)]\tLoss: 0.005518\n",
      "Train Epoch: 6 [7500/8000 (94%)]\tLoss: 0.089502\n",
      "\n",
      "Test set: Average loss: 0.0425, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/8000 (0%)]\tLoss: 0.004865\n",
      "Train Epoch: 7 [500/8000 (6%)]\tLoss: 0.231228\n",
      "Train Epoch: 7 [1000/8000 (12%)]\tLoss: 0.003466\n",
      "Train Epoch: 7 [1500/8000 (19%)]\tLoss: 0.015877\n",
      "Train Epoch: 7 [2000/8000 (25%)]\tLoss: 0.018806\n",
      "Train Epoch: 7 [2500/8000 (31%)]\tLoss: 0.185099\n",
      "Train Epoch: 7 [3000/8000 (38%)]\tLoss: 0.106089\n",
      "Train Epoch: 7 [3500/8000 (44%)]\tLoss: 0.010092\n",
      "Train Epoch: 7 [4000/8000 (50%)]\tLoss: 0.103695\n",
      "Train Epoch: 7 [4500/8000 (56%)]\tLoss: 0.012154\n",
      "Train Epoch: 7 [5000/8000 (62%)]\tLoss: 0.099751\n",
      "Train Epoch: 7 [5500/8000 (69%)]\tLoss: 0.249293\n",
      "Train Epoch: 7 [6000/8000 (75%)]\tLoss: 0.088031\n",
      "Train Epoch: 7 [6500/8000 (81%)]\tLoss: 0.107122\n",
      "Train Epoch: 7 [7000/8000 (88%)]\tLoss: 0.010072\n",
      "Train Epoch: 7 [7500/8000 (94%)]\tLoss: 0.014873\n",
      "\n",
      "Test set: Average loss: 0.0571, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/8000 (0%)]\tLoss: 0.102228\n",
      "Train Epoch: 8 [500/8000 (6%)]\tLoss: 0.100664\n",
      "Train Epoch: 8 [1000/8000 (12%)]\tLoss: 0.103515\n",
      "Train Epoch: 8 [1500/8000 (19%)]\tLoss: 0.096624\n",
      "Train Epoch: 8 [2000/8000 (25%)]\tLoss: 0.018938\n",
      "Train Epoch: 8 [2500/8000 (31%)]\tLoss: 0.008338\n",
      "Train Epoch: 8 [3000/8000 (38%)]\tLoss: 0.005063\n",
      "Train Epoch: 8 [3500/8000 (44%)]\tLoss: 0.008620\n",
      "Train Epoch: 8 [4000/8000 (50%)]\tLoss: 0.077098\n",
      "Train Epoch: 8 [4500/8000 (56%)]\tLoss: 0.017648\n",
      "Train Epoch: 8 [5000/8000 (62%)]\tLoss: 0.017556\n",
      "Train Epoch: 8 [5500/8000 (69%)]\tLoss: 0.242286\n",
      "Train Epoch: 8 [6000/8000 (75%)]\tLoss: 0.083255\n",
      "Train Epoch: 8 [6500/8000 (81%)]\tLoss: 0.010761\n",
      "Train Epoch: 8 [7000/8000 (88%)]\tLoss: 0.095719\n",
      "Train Epoch: 8 [7500/8000 (94%)]\tLoss: 0.064346\n",
      "\n",
      "Test set: Average loss: 0.0490, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/8000 (0%)]\tLoss: 0.010449\n",
      "Train Epoch: 9 [500/8000 (6%)]\tLoss: 0.059143\n",
      "Train Epoch: 9 [1000/8000 (12%)]\tLoss: 0.228011\n",
      "Train Epoch: 9 [1500/8000 (19%)]\tLoss: 0.094010\n",
      "Train Epoch: 9 [2000/8000 (25%)]\tLoss: 0.052268\n",
      "Train Epoch: 9 [2500/8000 (31%)]\tLoss: 0.003711\n",
      "Train Epoch: 9 [3000/8000 (38%)]\tLoss: 0.003947\n",
      "Train Epoch: 9 [3500/8000 (44%)]\tLoss: 0.096021\n",
      "Train Epoch: 9 [4000/8000 (50%)]\tLoss: 0.009040\n",
      "Train Epoch: 9 [4500/8000 (56%)]\tLoss: 0.013033\n",
      "Train Epoch: 9 [5000/8000 (62%)]\tLoss: 0.009936\n",
      "Train Epoch: 9 [5500/8000 (69%)]\tLoss: 0.093747\n",
      "Train Epoch: 9 [6000/8000 (75%)]\tLoss: 0.195727\n",
      "Train Epoch: 9 [6500/8000 (81%)]\tLoss: 0.079901\n",
      "Train Epoch: 9 [7000/8000 (88%)]\tLoss: 0.013275\n",
      "Train Epoch: 9 [7500/8000 (94%)]\tLoss: 0.084982\n",
      "\n",
      "Test set: Average loss: 0.0568, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/8000 (0%)]\tLoss: 0.012455\n",
      "Train Epoch: 10 [500/8000 (6%)]\tLoss: 0.008879\n",
      "Train Epoch: 10 [1000/8000 (12%)]\tLoss: 0.008726\n",
      "Train Epoch: 10 [1500/8000 (19%)]\tLoss: 0.154901\n",
      "Train Epoch: 10 [2000/8000 (25%)]\tLoss: 0.094473\n",
      "Train Epoch: 10 [2500/8000 (31%)]\tLoss: 0.055141\n",
      "Train Epoch: 10 [3000/8000 (38%)]\tLoss: 0.001508\n",
      "Train Epoch: 10 [3500/8000 (44%)]\tLoss: 0.003412\n",
      "Train Epoch: 10 [4000/8000 (50%)]\tLoss: 0.009258\n",
      "Train Epoch: 10 [4500/8000 (56%)]\tLoss: 0.014467\n",
      "Train Epoch: 10 [5000/8000 (62%)]\tLoss: 0.139418\n",
      "Train Epoch: 10 [5500/8000 (69%)]\tLoss: 0.067173\n",
      "Train Epoch: 10 [6000/8000 (75%)]\tLoss: 0.018075\n",
      "Train Epoch: 10 [6500/8000 (81%)]\tLoss: 0.091047\n",
      "Train Epoch: 10 [7000/8000 (88%)]\tLoss: 0.216162\n",
      "Train Epoch: 10 [7500/8000 (94%)]\tLoss: 0.009489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0527, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/8000 (0%)]\tLoss: 0.095484\n",
      "Train Epoch: 11 [500/8000 (6%)]\tLoss: 0.062220\n",
      "Train Epoch: 11 [1000/8000 (12%)]\tLoss: 0.035056\n",
      "Train Epoch: 11 [1500/8000 (19%)]\tLoss: 0.040849\n",
      "Train Epoch: 11 [2000/8000 (25%)]\tLoss: 0.137797\n",
      "Train Epoch: 11 [2500/8000 (31%)]\tLoss: 0.119528\n",
      "Train Epoch: 11 [3000/8000 (38%)]\tLoss: 0.005539\n",
      "Train Epoch: 11 [3500/8000 (44%)]\tLoss: 0.007124\n",
      "Train Epoch: 11 [4000/8000 (50%)]\tLoss: 0.085504\n",
      "Train Epoch: 11 [4500/8000 (56%)]\tLoss: 0.103717\n",
      "Train Epoch: 11 [5000/8000 (62%)]\tLoss: 0.017811\n",
      "Train Epoch: 11 [5500/8000 (69%)]\tLoss: 0.017212\n",
      "Train Epoch: 11 [6000/8000 (75%)]\tLoss: 0.159510\n",
      "Train Epoch: 11 [6500/8000 (81%)]\tLoss: 0.102285\n",
      "Train Epoch: 11 [7000/8000 (88%)]\tLoss: 0.060289\n",
      "Train Epoch: 11 [7500/8000 (94%)]\tLoss: 0.016150\n",
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/8000 (0%)]\tLoss: 0.007580\n",
      "Train Epoch: 12 [500/8000 (6%)]\tLoss: 0.117576\n",
      "Train Epoch: 12 [1000/8000 (12%)]\tLoss: 0.094350\n",
      "Train Epoch: 12 [1500/8000 (19%)]\tLoss: 0.058739\n",
      "Train Epoch: 12 [2000/8000 (25%)]\tLoss: 0.022223\n",
      "Train Epoch: 12 [2500/8000 (31%)]\tLoss: 0.013611\n",
      "Train Epoch: 12 [3000/8000 (38%)]\tLoss: 0.004835\n",
      "Train Epoch: 12 [3500/8000 (44%)]\tLoss: 0.009907\n",
      "Train Epoch: 12 [4000/8000 (50%)]\tLoss: 0.028662\n",
      "Train Epoch: 12 [4500/8000 (56%)]\tLoss: 0.000734\n",
      "Train Epoch: 12 [5000/8000 (62%)]\tLoss: 0.034042\n",
      "Train Epoch: 12 [5500/8000 (69%)]\tLoss: 0.016419\n",
      "Train Epoch: 12 [6000/8000 (75%)]\tLoss: 0.001586\n",
      "Train Epoch: 12 [6500/8000 (81%)]\tLoss: 0.002063\n",
      "Train Epoch: 12 [7000/8000 (88%)]\tLoss: 0.061744\n",
      "Train Epoch: 12 [7500/8000 (94%)]\tLoss: 0.006528\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/8000 (0%)]\tLoss: 0.103526\n",
      "Train Epoch: 13 [500/8000 (6%)]\tLoss: 0.010794\n",
      "Train Epoch: 13 [1000/8000 (12%)]\tLoss: 0.069246\n",
      "Train Epoch: 13 [1500/8000 (19%)]\tLoss: 0.000714\n",
      "Train Epoch: 13 [2000/8000 (25%)]\tLoss: 0.055639\n",
      "Train Epoch: 13 [2500/8000 (31%)]\tLoss: 0.046318\n",
      "Train Epoch: 13 [3000/8000 (38%)]\tLoss: 0.002493\n",
      "Train Epoch: 13 [3500/8000 (44%)]\tLoss: 0.006381\n",
      "Train Epoch: 13 [4000/8000 (50%)]\tLoss: 0.004205\n",
      "Train Epoch: 13 [4500/8000 (56%)]\tLoss: 0.001179\n",
      "Train Epoch: 13 [5000/8000 (62%)]\tLoss: 0.032511\n",
      "Train Epoch: 13 [5500/8000 (69%)]\tLoss: 0.050398\n",
      "Train Epoch: 13 [6000/8000 (75%)]\tLoss: 0.187098\n",
      "Train Epoch: 13 [6500/8000 (81%)]\tLoss: 0.003797\n",
      "Train Epoch: 13 [7000/8000 (88%)]\tLoss: 0.087864\n",
      "Train Epoch: 13 [7500/8000 (94%)]\tLoss: 0.002883\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/8000 (0%)]\tLoss: 0.025483\n",
      "Train Epoch: 14 [500/8000 (6%)]\tLoss: 0.018347\n",
      "Train Epoch: 14 [1000/8000 (12%)]\tLoss: 0.065157\n",
      "Train Epoch: 14 [1500/8000 (19%)]\tLoss: 0.029782\n",
      "Train Epoch: 14 [2000/8000 (25%)]\tLoss: 0.052051\n",
      "Train Epoch: 14 [2500/8000 (31%)]\tLoss: 0.002527\n",
      "Train Epoch: 14 [3000/8000 (38%)]\tLoss: 0.004033\n",
      "Train Epoch: 14 [3500/8000 (44%)]\tLoss: 0.007084\n",
      "Train Epoch: 14 [4000/8000 (50%)]\tLoss: 0.025807\n",
      "Train Epoch: 14 [4500/8000 (56%)]\tLoss: 0.013045\n",
      "Train Epoch: 14 [5000/8000 (62%)]\tLoss: 0.019104\n",
      "Train Epoch: 14 [5500/8000 (69%)]\tLoss: 0.020587\n",
      "Train Epoch: 14 [6000/8000 (75%)]\tLoss: 0.040576\n",
      "Train Epoch: 14 [6500/8000 (81%)]\tLoss: 0.016519\n",
      "Train Epoch: 14 [7000/8000 (88%)]\tLoss: 0.078141\n",
      "Train Epoch: 14 [7500/8000 (94%)]\tLoss: 0.003303\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 1979/2000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/8000 (0%)]\tLoss: 0.004655\n",
      "Train Epoch: 15 [500/8000 (6%)]\tLoss: 0.035623\n",
      "Train Epoch: 15 [1000/8000 (12%)]\tLoss: 0.001799\n",
      "Train Epoch: 15 [1500/8000 (19%)]\tLoss: 0.044941\n",
      "Train Epoch: 15 [2000/8000 (25%)]\tLoss: 0.035404\n",
      "Train Epoch: 15 [2500/8000 (31%)]\tLoss: 0.019212\n",
      "Train Epoch: 15 [3000/8000 (38%)]\tLoss: 0.035624\n",
      "Train Epoch: 15 [3500/8000 (44%)]\tLoss: 0.000957\n",
      "Train Epoch: 15 [4000/8000 (50%)]\tLoss: 0.002512\n",
      "Train Epoch: 15 [4500/8000 (56%)]\tLoss: 0.015287\n",
      "Train Epoch: 15 [5000/8000 (62%)]\tLoss: 0.001487\n",
      "Train Epoch: 15 [5500/8000 (69%)]\tLoss: 0.011887\n",
      "Train Epoch: 15 [6000/8000 (75%)]\tLoss: 0.013095\n",
      "Train Epoch: 15 [6500/8000 (81%)]\tLoss: 0.015700\n",
      "Train Epoch: 15 [7000/8000 (88%)]\tLoss: 0.058283\n",
      "Train Epoch: 15 [7500/8000 (94%)]\tLoss: 0.001545\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1981/2000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/8000 (0%)]\tLoss: 0.002072\n",
      "Train Epoch: 16 [500/8000 (6%)]\tLoss: 0.015059\n",
      "Train Epoch: 16 [1000/8000 (12%)]\tLoss: 0.045533\n",
      "Train Epoch: 16 [1500/8000 (19%)]\tLoss: 0.009306\n",
      "Train Epoch: 16 [2000/8000 (25%)]\tLoss: 0.001135\n",
      "Train Epoch: 16 [2500/8000 (31%)]\tLoss: 0.004161\n",
      "Train Epoch: 16 [3000/8000 (38%)]\tLoss: 0.004427\n",
      "Train Epoch: 16 [3500/8000 (44%)]\tLoss: 0.007262\n",
      "Train Epoch: 16 [4000/8000 (50%)]\tLoss: 0.006297\n",
      "Train Epoch: 16 [4500/8000 (56%)]\tLoss: 0.000620\n",
      "Train Epoch: 16 [5000/8000 (62%)]\tLoss: 0.006158\n",
      "Train Epoch: 16 [5500/8000 (69%)]\tLoss: 0.092469\n",
      "Train Epoch: 16 [6000/8000 (75%)]\tLoss: 0.001390\n",
      "Train Epoch: 16 [6500/8000 (81%)]\tLoss: 0.006516\n",
      "Train Epoch: 16 [7000/8000 (88%)]\tLoss: 0.002150\n",
      "Train Epoch: 16 [7500/8000 (94%)]\tLoss: 0.002411\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1981/2000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/8000 (0%)]\tLoss: 0.023765\n",
      "Train Epoch: 17 [500/8000 (6%)]\tLoss: 0.000748\n",
      "Train Epoch: 17 [1000/8000 (12%)]\tLoss: 0.002921\n",
      "Train Epoch: 17 [1500/8000 (19%)]\tLoss: 0.005681\n",
      "Train Epoch: 17 [2000/8000 (25%)]\tLoss: 0.000535\n",
      "Train Epoch: 17 [2500/8000 (31%)]\tLoss: 0.000272\n",
      "Train Epoch: 17 [3000/8000 (38%)]\tLoss: 0.009609\n",
      "Train Epoch: 17 [3500/8000 (44%)]\tLoss: 0.078699\n",
      "Train Epoch: 17 [4000/8000 (50%)]\tLoss: 0.031520\n",
      "Train Epoch: 17 [4500/8000 (56%)]\tLoss: 0.010326\n",
      "Train Epoch: 17 [5000/8000 (62%)]\tLoss: 0.011455\n",
      "Train Epoch: 17 [5500/8000 (69%)]\tLoss: 0.001724\n",
      "Train Epoch: 17 [6000/8000 (75%)]\tLoss: 0.006776\n",
      "Train Epoch: 17 [6500/8000 (81%)]\tLoss: 0.003037\n",
      "Train Epoch: 17 [7000/8000 (88%)]\tLoss: 0.010400\n",
      "Train Epoch: 17 [7500/8000 (94%)]\tLoss: 0.003011\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 18 [0/8000 (0%)]\tLoss: 0.003161\n",
      "Train Epoch: 18 [500/8000 (6%)]\tLoss: 0.003399\n",
      "Train Epoch: 18 [1000/8000 (12%)]\tLoss: 0.000148\n",
      "Train Epoch: 18 [1500/8000 (19%)]\tLoss: 0.000417\n",
      "Train Epoch: 18 [2000/8000 (25%)]\tLoss: 0.006903\n",
      "Train Epoch: 18 [2500/8000 (31%)]\tLoss: 0.001389\n",
      "Train Epoch: 18 [3000/8000 (38%)]\tLoss: 0.009431\n",
      "Train Epoch: 18 [3500/8000 (44%)]\tLoss: 0.001855\n",
      "Train Epoch: 18 [4000/8000 (50%)]\tLoss: 0.017892\n",
      "Train Epoch: 18 [4500/8000 (56%)]\tLoss: 0.002787\n",
      "Train Epoch: 18 [5000/8000 (62%)]\tLoss: 0.000434\n",
      "Train Epoch: 18 [5500/8000 (69%)]\tLoss: 0.006981\n",
      "Train Epoch: 18 [6000/8000 (75%)]\tLoss: 0.030747\n",
      "Train Epoch: 18 [6500/8000 (81%)]\tLoss: 0.000309\n",
      "Train Epoch: 18 [7000/8000 (88%)]\tLoss: 0.015544\n",
      "Train Epoch: 18 [7500/8000 (94%)]\tLoss: 0.004533\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 1994/2000 (100%)\n",
      "\n",
      "Train Epoch: 19 [0/8000 (0%)]\tLoss: 0.004622\n",
      "Train Epoch: 19 [500/8000 (6%)]\tLoss: 0.010636\n",
      "Train Epoch: 19 [1000/8000 (12%)]\tLoss: 0.006894\n",
      "Train Epoch: 19 [1500/8000 (19%)]\tLoss: 0.025059\n",
      "Train Epoch: 19 [2000/8000 (25%)]\tLoss: 0.000803\n",
      "Train Epoch: 19 [2500/8000 (31%)]\tLoss: 0.114148\n",
      "Train Epoch: 19 [3000/8000 (38%)]\tLoss: 0.016724\n",
      "Train Epoch: 19 [3500/8000 (44%)]\tLoss: 0.000610\n",
      "Train Epoch: 19 [4000/8000 (50%)]\tLoss: 0.000216\n",
      "Train Epoch: 19 [4500/8000 (56%)]\tLoss: 0.010791\n",
      "Train Epoch: 19 [5000/8000 (62%)]\tLoss: 0.004089\n",
      "Train Epoch: 19 [5500/8000 (69%)]\tLoss: 0.004561\n",
      "Train Epoch: 19 [6000/8000 (75%)]\tLoss: 0.004126\n",
      "Train Epoch: 19 [6500/8000 (81%)]\tLoss: 0.007736\n",
      "Train Epoch: 19 [7000/8000 (88%)]\tLoss: 0.019224\n",
      "Train Epoch: 19 [7500/8000 (94%)]\tLoss: 0.031058\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 1990/2000 (100%)\n",
      "\n",
      "Train Epoch: 20 [0/8000 (0%)]\tLoss: 0.000556\n",
      "Train Epoch: 20 [500/8000 (6%)]\tLoss: 0.007535\n",
      "Train Epoch: 20 [1000/8000 (12%)]\tLoss: 0.000617\n",
      "Train Epoch: 20 [1500/8000 (19%)]\tLoss: 0.000660\n",
      "Train Epoch: 20 [2000/8000 (25%)]\tLoss: 0.003809\n",
      "Train Epoch: 20 [2500/8000 (31%)]\tLoss: 0.018364\n",
      "Train Epoch: 20 [3000/8000 (38%)]\tLoss: 0.016861\n",
      "Train Epoch: 20 [3500/8000 (44%)]\tLoss: 0.007024\n",
      "Train Epoch: 20 [4000/8000 (50%)]\tLoss: 0.003340\n",
      "Train Epoch: 20 [4500/8000 (56%)]\tLoss: 0.001329\n",
      "Train Epoch: 20 [5000/8000 (62%)]\tLoss: 0.100950\n",
      "Train Epoch: 20 [5500/8000 (69%)]\tLoss: 0.024139\n",
      "Train Epoch: 20 [6000/8000 (75%)]\tLoss: 0.013240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [6500/8000 (81%)]\tLoss: 0.000497\n",
      "Train Epoch: 20 [7000/8000 (88%)]\tLoss: 0.076206\n",
      "Train Epoch: 20 [7500/8000 (94%)]\tLoss: 0.000498\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 1982/2000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/8000 (0%)]\tLoss: 0.057912\n",
      "Train Epoch: 21 [500/8000 (6%)]\tLoss: 0.025210\n",
      "Train Epoch: 21 [1000/8000 (12%)]\tLoss: 0.048594\n",
      "Train Epoch: 21 [1500/8000 (19%)]\tLoss: 0.020346\n",
      "Train Epoch: 21 [2000/8000 (25%)]\tLoss: 0.000067\n",
      "Train Epoch: 21 [2500/8000 (31%)]\tLoss: 0.000380\n",
      "Train Epoch: 21 [3000/8000 (38%)]\tLoss: 0.002571\n",
      "Train Epoch: 21 [3500/8000 (44%)]\tLoss: 0.012676\n",
      "Train Epoch: 21 [4000/8000 (50%)]\tLoss: 0.000590\n",
      "Train Epoch: 21 [4500/8000 (56%)]\tLoss: 0.019656\n",
      "Train Epoch: 21 [5000/8000 (62%)]\tLoss: 0.004258\n",
      "Train Epoch: 21 [5500/8000 (69%)]\tLoss: 0.053142\n",
      "Train Epoch: 21 [6000/8000 (75%)]\tLoss: 0.005787\n",
      "Train Epoch: 21 [6500/8000 (81%)]\tLoss: 0.000511\n",
      "Train Epoch: 21 [7000/8000 (88%)]\tLoss: 0.003405\n",
      "Train Epoch: 21 [7500/8000 (94%)]\tLoss: 0.000789\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 1992/2000 (100%)\n",
      "\n",
      "Train Epoch: 22 [0/8000 (0%)]\tLoss: 0.000125\n",
      "Train Epoch: 22 [500/8000 (6%)]\tLoss: 0.000124\n",
      "Train Epoch: 22 [1000/8000 (12%)]\tLoss: 0.007564\n",
      "Train Epoch: 22 [1500/8000 (19%)]\tLoss: 0.015434\n",
      "Train Epoch: 22 [2000/8000 (25%)]\tLoss: 0.018984\n",
      "Train Epoch: 22 [2500/8000 (31%)]\tLoss: 0.004640\n",
      "Train Epoch: 22 [3000/8000 (38%)]\tLoss: 0.000815\n",
      "Train Epoch: 22 [3500/8000 (44%)]\tLoss: 0.001102\n",
      "Train Epoch: 22 [4000/8000 (50%)]\tLoss: 0.038402\n",
      "Train Epoch: 22 [4500/8000 (56%)]\tLoss: 0.006144\n",
      "Train Epoch: 22 [5000/8000 (62%)]\tLoss: 0.028725\n",
      "Train Epoch: 22 [5500/8000 (69%)]\tLoss: 0.000125\n",
      "Train Epoch: 22 [6000/8000 (75%)]\tLoss: 0.012481\n",
      "Train Epoch: 22 [6500/8000 (81%)]\tLoss: 0.000703\n",
      "Train Epoch: 22 [7000/8000 (88%)]\tLoss: 0.005644\n",
      "Train Epoch: 22 [7500/8000 (94%)]\tLoss: 0.004304\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 1984/2000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/8000 (0%)]\tLoss: 0.009865\n",
      "Train Epoch: 23 [500/8000 (6%)]\tLoss: 0.000078\n",
      "Train Epoch: 23 [1000/8000 (12%)]\tLoss: 0.019045\n",
      "Train Epoch: 23 [1500/8000 (19%)]\tLoss: 0.020124\n",
      "Train Epoch: 23 [2000/8000 (25%)]\tLoss: 0.004219\n",
      "Train Epoch: 23 [2500/8000 (31%)]\tLoss: 0.000093\n",
      "Train Epoch: 23 [3000/8000 (38%)]\tLoss: 0.005980\n",
      "Train Epoch: 23 [3500/8000 (44%)]\tLoss: 0.002629\n",
      "Train Epoch: 23 [4000/8000 (50%)]\tLoss: 0.014167\n",
      "Train Epoch: 23 [4500/8000 (56%)]\tLoss: 0.033085\n",
      "Train Epoch: 23 [5000/8000 (62%)]\tLoss: 0.001050\n",
      "Train Epoch: 23 [5500/8000 (69%)]\tLoss: 0.046818\n",
      "Train Epoch: 23 [6000/8000 (75%)]\tLoss: 0.013250\n",
      "Train Epoch: 23 [6500/8000 (81%)]\tLoss: 0.000160\n",
      "Train Epoch: 23 [7000/8000 (88%)]\tLoss: 0.029837\n",
      "Train Epoch: 23 [7500/8000 (94%)]\tLoss: 0.000389\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 1989/2000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/8000 (0%)]\tLoss: 0.002824\n",
      "Train Epoch: 24 [500/8000 (6%)]\tLoss: 0.061121\n",
      "Train Epoch: 24 [1000/8000 (12%)]\tLoss: 0.000195\n",
      "Train Epoch: 24 [1500/8000 (19%)]\tLoss: 0.014928\n",
      "Train Epoch: 24 [2000/8000 (25%)]\tLoss: 0.002238\n",
      "Train Epoch: 24 [2500/8000 (31%)]\tLoss: 0.007601\n",
      "Train Epoch: 24 [3000/8000 (38%)]\tLoss: 0.000332\n",
      "Train Epoch: 24 [3500/8000 (44%)]\tLoss: 0.000082\n",
      "Train Epoch: 24 [4000/8000 (50%)]\tLoss: 0.000417\n",
      "Train Epoch: 24 [4500/8000 (56%)]\tLoss: 0.042162\n",
      "Train Epoch: 24 [5000/8000 (62%)]\tLoss: 0.005556\n",
      "Train Epoch: 24 [5500/8000 (69%)]\tLoss: 0.004467\n",
      "Train Epoch: 24 [6000/8000 (75%)]\tLoss: 0.001592\n",
      "Train Epoch: 24 [6500/8000 (81%)]\tLoss: 0.029187\n",
      "Train Epoch: 24 [7000/8000 (88%)]\tLoss: 0.002948\n",
      "Train Epoch: 24 [7500/8000 (94%)]\tLoss: 0.000466\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 1993/2000 (100%)\n",
      "\n",
      "Train Epoch: 25 [0/8000 (0%)]\tLoss: 0.000045\n",
      "Train Epoch: 25 [500/8000 (6%)]\tLoss: 0.051647\n",
      "Train Epoch: 25 [1000/8000 (12%)]\tLoss: 0.000092\n",
      "Train Epoch: 25 [1500/8000 (19%)]\tLoss: 0.002213\n",
      "Train Epoch: 25 [2000/8000 (25%)]\tLoss: 0.009862\n",
      "Train Epoch: 25 [2500/8000 (31%)]\tLoss: 0.014778\n",
      "Train Epoch: 25 [3000/8000 (38%)]\tLoss: 0.003131\n",
      "Train Epoch: 25 [3500/8000 (44%)]\tLoss: 0.009897\n",
      "Train Epoch: 25 [4000/8000 (50%)]\tLoss: 0.010964\n",
      "Train Epoch: 25 [4500/8000 (56%)]\tLoss: 0.000863\n",
      "Train Epoch: 25 [5000/8000 (62%)]\tLoss: 0.019820\n",
      "Train Epoch: 25 [5500/8000 (69%)]\tLoss: 0.009078\n",
      "Train Epoch: 25 [6000/8000 (75%)]\tLoss: 0.001967\n",
      "Train Epoch: 25 [6500/8000 (81%)]\tLoss: 0.000699\n",
      "Train Epoch: 25 [7000/8000 (88%)]\tLoss: 0.000022\n",
      "Train Epoch: 25 [7500/8000 (94%)]\tLoss: 0.002406\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/8000 (0%)]\tLoss: 0.004609\n",
      "Train Epoch: 26 [500/8000 (6%)]\tLoss: 0.002178\n",
      "Train Epoch: 26 [1000/8000 (12%)]\tLoss: 0.031917\n",
      "Train Epoch: 26 [1500/8000 (19%)]\tLoss: 0.000136\n",
      "Train Epoch: 26 [2000/8000 (25%)]\tLoss: 0.032489\n",
      "Train Epoch: 26 [2500/8000 (31%)]\tLoss: 0.004140\n",
      "Train Epoch: 26 [3000/8000 (38%)]\tLoss: 0.000053\n",
      "Train Epoch: 26 [3500/8000 (44%)]\tLoss: 0.006617\n",
      "Train Epoch: 26 [4000/8000 (50%)]\tLoss: 0.000051\n",
      "Train Epoch: 26 [4500/8000 (56%)]\tLoss: 0.005192\n",
      "Train Epoch: 26 [5000/8000 (62%)]\tLoss: 0.022203\n",
      "Train Epoch: 26 [5500/8000 (69%)]\tLoss: 0.000531\n",
      "Train Epoch: 26 [6000/8000 (75%)]\tLoss: 0.016297\n",
      "Train Epoch: 26 [6500/8000 (81%)]\tLoss: 0.010116\n",
      "Train Epoch: 26 [7000/8000 (88%)]\tLoss: 0.000388\n",
      "Train Epoch: 26 [7500/8000 (94%)]\tLoss: 0.012665\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 1993/2000 (100%)\n",
      "\n",
      "Train Epoch: 27 [0/8000 (0%)]\tLoss: 0.002365\n",
      "Train Epoch: 27 [500/8000 (6%)]\tLoss: 0.000778\n",
      "Train Epoch: 27 [1000/8000 (12%)]\tLoss: 0.006744\n",
      "Train Epoch: 27 [1500/8000 (19%)]\tLoss: 0.004597\n",
      "Train Epoch: 27 [2000/8000 (25%)]\tLoss: 0.008059\n",
      "Train Epoch: 27 [2500/8000 (31%)]\tLoss: 0.002093\n",
      "Train Epoch: 27 [3000/8000 (38%)]\tLoss: 0.000151\n",
      "Train Epoch: 27 [3500/8000 (44%)]\tLoss: 0.042429\n",
      "Train Epoch: 27 [4000/8000 (50%)]\tLoss: 0.000539\n",
      "Train Epoch: 27 [4500/8000 (56%)]\tLoss: 0.000320\n",
      "Train Epoch: 27 [5000/8000 (62%)]\tLoss: 0.032466\n",
      "Train Epoch: 27 [5500/8000 (69%)]\tLoss: 0.000226\n",
      "Train Epoch: 27 [6000/8000 (75%)]\tLoss: 0.022080\n",
      "Train Epoch: 27 [6500/8000 (81%)]\tLoss: 0.017709\n",
      "Train Epoch: 27 [7000/8000 (88%)]\tLoss: 0.006038\n",
      "Train Epoch: 27 [7500/8000 (94%)]\tLoss: 0.007555\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 1996/2000 (100%)\n",
      "\n",
      "Train Epoch: 28 [0/8000 (0%)]\tLoss: 0.000456\n",
      "Train Epoch: 28 [500/8000 (6%)]\tLoss: 0.002924\n",
      "Train Epoch: 28 [1000/8000 (12%)]\tLoss: 0.052392\n",
      "Train Epoch: 28 [1500/8000 (19%)]\tLoss: 0.005613\n",
      "Train Epoch: 28 [2000/8000 (25%)]\tLoss: 0.001490\n",
      "Train Epoch: 28 [2500/8000 (31%)]\tLoss: 0.018729\n",
      "Train Epoch: 28 [3000/8000 (38%)]\tLoss: 0.000941\n",
      "Train Epoch: 28 [3500/8000 (44%)]\tLoss: 0.001047\n",
      "Train Epoch: 28 [4000/8000 (50%)]\tLoss: 0.016959\n",
      "Train Epoch: 28 [4500/8000 (56%)]\tLoss: 0.058981\n",
      "Train Epoch: 28 [5000/8000 (62%)]\tLoss: 0.000069\n",
      "Train Epoch: 28 [5500/8000 (69%)]\tLoss: 0.002743\n",
      "Train Epoch: 28 [6000/8000 (75%)]\tLoss: 0.013245\n",
      "Train Epoch: 28 [6500/8000 (81%)]\tLoss: 0.000127\n",
      "Train Epoch: 28 [7000/8000 (88%)]\tLoss: 0.005774\n",
      "Train Epoch: 28 [7500/8000 (94%)]\tLoss: 0.000225\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/8000 (0%)]\tLoss: 0.046509\n",
      "Train Epoch: 29 [500/8000 (6%)]\tLoss: 0.010880\n",
      "Train Epoch: 29 [1000/8000 (12%)]\tLoss: 0.004389\n",
      "Train Epoch: 29 [1500/8000 (19%)]\tLoss: 0.000154\n",
      "Train Epoch: 29 [2000/8000 (25%)]\tLoss: 0.052921\n",
      "Train Epoch: 29 [2500/8000 (31%)]\tLoss: 0.001870\n",
      "Train Epoch: 29 [3000/8000 (38%)]\tLoss: 0.007868\n",
      "Train Epoch: 29 [3500/8000 (44%)]\tLoss: 0.045370\n",
      "Train Epoch: 29 [4000/8000 (50%)]\tLoss: 0.057502\n",
      "Train Epoch: 29 [4500/8000 (56%)]\tLoss: 0.002013\n",
      "Train Epoch: 29 [5000/8000 (62%)]\tLoss: 0.001172\n",
      "Train Epoch: 29 [5500/8000 (69%)]\tLoss: 0.001882\n",
      "Train Epoch: 29 [6000/8000 (75%)]\tLoss: 0.000236\n",
      "Train Epoch: 29 [6500/8000 (81%)]\tLoss: 0.018905\n",
      "Train Epoch: 29 [7000/8000 (88%)]\tLoss: 0.001352\n",
      "Train Epoch: 29 [7500/8000 (94%)]\tLoss: 0.001898\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/8000 (0%)]\tLoss: 0.003050\n",
      "Train Epoch: 30 [500/8000 (6%)]\tLoss: 0.005661\n",
      "Train Epoch: 30 [1000/8000 (12%)]\tLoss: 0.005908\n",
      "Train Epoch: 30 [1500/8000 (19%)]\tLoss: 0.000473\n",
      "Train Epoch: 30 [2000/8000 (25%)]\tLoss: 0.006669\n",
      "Train Epoch: 30 [2500/8000 (31%)]\tLoss: 0.000758\n",
      "Train Epoch: 30 [3000/8000 (38%)]\tLoss: 0.000736\n",
      "Train Epoch: 30 [3500/8000 (44%)]\tLoss: 0.007292\n",
      "Train Epoch: 30 [4000/8000 (50%)]\tLoss: 0.002467\n",
      "Train Epoch: 30 [4500/8000 (56%)]\tLoss: 0.002404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [5000/8000 (62%)]\tLoss: 0.055923\n",
      "Train Epoch: 30 [5500/8000 (69%)]\tLoss: 0.001260\n",
      "Train Epoch: 30 [6000/8000 (75%)]\tLoss: 0.003101\n",
      "Train Epoch: 30 [6500/8000 (81%)]\tLoss: 0.000346\n",
      "Train Epoch: 30 [7000/8000 (88%)]\tLoss: 0.021534\n",
      "Train Epoch: 30 [7500/8000 (94%)]\tLoss: 0.002217\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 1993/2000 (100%)\n",
      "\n",
      "Train Epoch: 31 [0/8000 (0%)]\tLoss: 0.019578\n",
      "Train Epoch: 31 [500/8000 (6%)]\tLoss: 0.053066\n",
      "Train Epoch: 31 [1000/8000 (12%)]\tLoss: 0.000340\n",
      "Train Epoch: 31 [1500/8000 (19%)]\tLoss: 0.004538\n",
      "Train Epoch: 31 [2000/8000 (25%)]\tLoss: 0.008996\n",
      "Train Epoch: 31 [2500/8000 (31%)]\tLoss: 0.000816\n",
      "Train Epoch: 31 [3000/8000 (38%)]\tLoss: 0.108974\n",
      "Train Epoch: 31 [3500/8000 (44%)]\tLoss: 0.000322\n",
      "Train Epoch: 31 [4000/8000 (50%)]\tLoss: 0.014705\n",
      "Train Epoch: 31 [4500/8000 (56%)]\tLoss: 0.000551\n",
      "Train Epoch: 31 [5000/8000 (62%)]\tLoss: 0.002847\n",
      "Train Epoch: 31 [5500/8000 (69%)]\tLoss: 0.022247\n",
      "Train Epoch: 31 [6000/8000 (75%)]\tLoss: 0.000351\n",
      "Train Epoch: 31 [6500/8000 (81%)]\tLoss: 0.007110\n",
      "Train Epoch: 31 [7000/8000 (88%)]\tLoss: 0.000083\n",
      "Train Epoch: 31 [7500/8000 (94%)]\tLoss: 0.025939\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 1992/2000 (100%)\n",
      "\n",
      "Train Epoch: 32 [0/8000 (0%)]\tLoss: 0.001516\n",
      "Train Epoch: 32 [500/8000 (6%)]\tLoss: 0.002205\n",
      "Train Epoch: 32 [1000/8000 (12%)]\tLoss: 0.001442\n",
      "Train Epoch: 32 [1500/8000 (19%)]\tLoss: 0.004789\n",
      "Train Epoch: 32 [2000/8000 (25%)]\tLoss: 0.027466\n",
      "Train Epoch: 32 [2500/8000 (31%)]\tLoss: 0.004191\n",
      "Train Epoch: 32 [3000/8000 (38%)]\tLoss: 0.009341\n",
      "Train Epoch: 32 [3500/8000 (44%)]\tLoss: 0.000958\n",
      "Train Epoch: 32 [4000/8000 (50%)]\tLoss: 0.008127\n",
      "Train Epoch: 32 [4500/8000 (56%)]\tLoss: 0.000673\n",
      "Train Epoch: 32 [5000/8000 (62%)]\tLoss: 0.000539\n",
      "Train Epoch: 32 [5500/8000 (69%)]\tLoss: 0.004736\n",
      "Train Epoch: 32 [6000/8000 (75%)]\tLoss: 0.010381\n",
      "Train Epoch: 32 [6500/8000 (81%)]\tLoss: 0.000097\n",
      "Train Epoch: 32 [7000/8000 (88%)]\tLoss: 0.000261\n",
      "Train Epoch: 32 [7500/8000 (94%)]\tLoss: 0.000138\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 1995/2000 (100%)\n",
      "\n",
      "Train Epoch: 33 [0/8000 (0%)]\tLoss: 0.006506\n",
      "Train Epoch: 33 [500/8000 (6%)]\tLoss: 0.000053\n",
      "Train Epoch: 33 [1000/8000 (12%)]\tLoss: 0.037813\n",
      "Train Epoch: 33 [1500/8000 (19%)]\tLoss: 0.002430\n",
      "Train Epoch: 33 [2000/8000 (25%)]\tLoss: 0.001086\n",
      "Train Epoch: 33 [2500/8000 (31%)]\tLoss: 0.001630\n",
      "Train Epoch: 33 [3000/8000 (38%)]\tLoss: 0.019410\n",
      "Train Epoch: 33 [3500/8000 (44%)]\tLoss: 0.001922\n",
      "Train Epoch: 33 [4000/8000 (50%)]\tLoss: 0.017616\n",
      "Train Epoch: 33 [4500/8000 (56%)]\tLoss: 0.001363\n",
      "Train Epoch: 33 [5000/8000 (62%)]\tLoss: 0.001772\n",
      "Train Epoch: 33 [5500/8000 (69%)]\tLoss: 0.026129\n",
      "Train Epoch: 33 [6000/8000 (75%)]\tLoss: 0.012788\n",
      "Train Epoch: 33 [6500/8000 (81%)]\tLoss: 0.020951\n",
      "Train Epoch: 33 [7000/8000 (88%)]\tLoss: 0.000651\n",
      "Train Epoch: 33 [7500/8000 (94%)]\tLoss: 0.014817\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 34 [0/8000 (0%)]\tLoss: 0.037452\n",
      "Train Epoch: 34 [500/8000 (6%)]\tLoss: 0.000791\n",
      "Train Epoch: 34 [1000/8000 (12%)]\tLoss: 0.004278\n",
      "Train Epoch: 34 [1500/8000 (19%)]\tLoss: 0.000564\n",
      "Train Epoch: 34 [2000/8000 (25%)]\tLoss: 0.001855\n",
      "Train Epoch: 34 [2500/8000 (31%)]\tLoss: 0.000346\n",
      "Train Epoch: 34 [3000/8000 (38%)]\tLoss: 0.005184\n",
      "Train Epoch: 34 [3500/8000 (44%)]\tLoss: 0.005033\n",
      "Train Epoch: 34 [4000/8000 (50%)]\tLoss: 0.000210\n",
      "Train Epoch: 34 [4500/8000 (56%)]\tLoss: 0.000178\n",
      "Train Epoch: 34 [5000/8000 (62%)]\tLoss: 0.013986\n",
      "Train Epoch: 34 [5500/8000 (69%)]\tLoss: 0.000747\n",
      "Train Epoch: 34 [6000/8000 (75%)]\tLoss: 0.003854\n",
      "Train Epoch: 34 [6500/8000 (81%)]\tLoss: 0.009583\n",
      "Train Epoch: 34 [7000/8000 (88%)]\tLoss: 0.000260\n",
      "Train Epoch: 34 [7500/8000 (94%)]\tLoss: 0.000280\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 1986/2000 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/8000 (0%)]\tLoss: 0.005835\n",
      "Train Epoch: 35 [500/8000 (6%)]\tLoss: 0.000135\n",
      "Train Epoch: 35 [1000/8000 (12%)]\tLoss: 0.004261\n",
      "Train Epoch: 35 [1500/8000 (19%)]\tLoss: 0.001239\n",
      "Train Epoch: 35 [2000/8000 (25%)]\tLoss: 0.000410\n",
      "Train Epoch: 35 [2500/8000 (31%)]\tLoss: 0.012391\n",
      "Train Epoch: 35 [3000/8000 (38%)]\tLoss: 0.000235\n",
      "Train Epoch: 35 [3500/8000 (44%)]\tLoss: 0.012174\n",
      "Train Epoch: 35 [4000/8000 (50%)]\tLoss: 0.069245\n",
      "Train Epoch: 35 [4500/8000 (56%)]\tLoss: 0.000553\n",
      "Train Epoch: 35 [5000/8000 (62%)]\tLoss: 0.000773\n",
      "Train Epoch: 35 [5500/8000 (69%)]\tLoss: 0.006966\n",
      "Train Epoch: 35 [6000/8000 (75%)]\tLoss: 0.001429\n",
      "Train Epoch: 35 [6500/8000 (81%)]\tLoss: 0.000033\n",
      "Train Epoch: 35 [7000/8000 (88%)]\tLoss: 0.000021\n",
      "Train Epoch: 35 [7500/8000 (94%)]\tLoss: 0.020092\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 1989/2000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/8000 (0%)]\tLoss: 0.000437\n",
      "Train Epoch: 36 [500/8000 (6%)]\tLoss: 0.007198\n",
      "Train Epoch: 36 [1000/8000 (12%)]\tLoss: 0.000120\n",
      "Train Epoch: 36 [1500/8000 (19%)]\tLoss: 0.034980\n",
      "Train Epoch: 36 [2000/8000 (25%)]\tLoss: 0.018502\n",
      "Train Epoch: 36 [2500/8000 (31%)]\tLoss: 0.002071\n",
      "Train Epoch: 36 [3000/8000 (38%)]\tLoss: 0.000113\n",
      "Train Epoch: 36 [3500/8000 (44%)]\tLoss: 0.003478\n",
      "Train Epoch: 36 [4000/8000 (50%)]\tLoss: 0.000545\n",
      "Train Epoch: 36 [4500/8000 (56%)]\tLoss: 0.001246\n",
      "Train Epoch: 36 [5000/8000 (62%)]\tLoss: 0.004431\n",
      "Train Epoch: 36 [5500/8000 (69%)]\tLoss: 0.087094\n",
      "Train Epoch: 36 [6000/8000 (75%)]\tLoss: 0.076581\n",
      "Train Epoch: 36 [6500/8000 (81%)]\tLoss: 0.011641\n",
      "Train Epoch: 36 [7000/8000 (88%)]\tLoss: 0.009813\n",
      "Train Epoch: 36 [7500/8000 (94%)]\tLoss: 0.000409\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 1982/2000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/8000 (0%)]\tLoss: 0.002247\n",
      "Train Epoch: 37 [500/8000 (6%)]\tLoss: 0.044797\n",
      "Train Epoch: 37 [1000/8000 (12%)]\tLoss: 0.020283\n",
      "Train Epoch: 37 [1500/8000 (19%)]\tLoss: 0.000307\n",
      "Train Epoch: 37 [2000/8000 (25%)]\tLoss: 0.003322\n",
      "Train Epoch: 37 [2500/8000 (31%)]\tLoss: 0.000857\n",
      "Train Epoch: 37 [3000/8000 (38%)]\tLoss: 0.000131\n",
      "Train Epoch: 37 [3500/8000 (44%)]\tLoss: 0.000508\n",
      "Train Epoch: 37 [4000/8000 (50%)]\tLoss: 0.002359\n",
      "Train Epoch: 37 [4500/8000 (56%)]\tLoss: 0.000033\n",
      "Train Epoch: 37 [5000/8000 (62%)]\tLoss: 0.004287\n",
      "Train Epoch: 37 [5500/8000 (69%)]\tLoss: 0.000330\n",
      "Train Epoch: 37 [6000/8000 (75%)]\tLoss: 0.001572\n",
      "Train Epoch: 37 [6500/8000 (81%)]\tLoss: 0.031140\n",
      "Train Epoch: 37 [7000/8000 (88%)]\tLoss: 0.003952\n",
      "Train Epoch: 37 [7500/8000 (94%)]\tLoss: 0.000038\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 38 [0/8000 (0%)]\tLoss: 0.016389\n",
      "Train Epoch: 38 [500/8000 (6%)]\tLoss: 0.000038\n",
      "Train Epoch: 38 [1000/8000 (12%)]\tLoss: 0.000099\n",
      "Train Epoch: 38 [1500/8000 (19%)]\tLoss: 0.003713\n",
      "Train Epoch: 38 [2000/8000 (25%)]\tLoss: 0.000069\n",
      "Train Epoch: 38 [2500/8000 (31%)]\tLoss: 0.000141\n",
      "Train Epoch: 38 [3000/8000 (38%)]\tLoss: 0.000029\n",
      "Train Epoch: 38 [3500/8000 (44%)]\tLoss: 0.012150\n",
      "Train Epoch: 38 [4000/8000 (50%)]\tLoss: 0.000706\n",
      "Train Epoch: 38 [4500/8000 (56%)]\tLoss: 0.000360\n",
      "Train Epoch: 38 [5000/8000 (62%)]\tLoss: 0.002555\n",
      "Train Epoch: 38 [5500/8000 (69%)]\tLoss: 0.001612\n",
      "Train Epoch: 38 [6000/8000 (75%)]\tLoss: 0.000341\n",
      "Train Epoch: 38 [6500/8000 (81%)]\tLoss: 0.028091\n",
      "Train Epoch: 38 [7000/8000 (88%)]\tLoss: 0.003057\n",
      "Train Epoch: 38 [7500/8000 (94%)]\tLoss: 0.000080\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 1996/2000 (100%)\n",
      "\n",
      "Train Epoch: 39 [0/8000 (0%)]\tLoss: 0.005846\n",
      "Train Epoch: 39 [500/8000 (6%)]\tLoss: 0.000037\n",
      "Train Epoch: 39 [1000/8000 (12%)]\tLoss: 0.000031\n",
      "Train Epoch: 39 [1500/8000 (19%)]\tLoss: 0.011935\n",
      "Train Epoch: 39 [2000/8000 (25%)]\tLoss: 0.000047\n",
      "Train Epoch: 39 [2500/8000 (31%)]\tLoss: 0.003468\n",
      "Train Epoch: 39 [3000/8000 (38%)]\tLoss: 0.004466\n",
      "Train Epoch: 39 [3500/8000 (44%)]\tLoss: 0.005685\n",
      "Train Epoch: 39 [4000/8000 (50%)]\tLoss: 0.005472\n",
      "Train Epoch: 39 [4500/8000 (56%)]\tLoss: 0.000421\n",
      "Train Epoch: 39 [5000/8000 (62%)]\tLoss: 0.072151\n",
      "Train Epoch: 39 [5500/8000 (69%)]\tLoss: 0.002573\n",
      "Train Epoch: 39 [6000/8000 (75%)]\tLoss: 0.000021\n",
      "Train Epoch: 39 [6500/8000 (81%)]\tLoss: 0.000145\n",
      "Train Epoch: 39 [7000/8000 (88%)]\tLoss: 0.012006\n",
      "Train Epoch: 39 [7500/8000 (94%)]\tLoss: 0.008557\n",
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 1996/2000 (100%)\n",
      "\n",
      "Train Epoch: 40 [0/8000 (0%)]\tLoss: 0.000226\n",
      "Train Epoch: 40 [500/8000 (6%)]\tLoss: 0.015248\n",
      "Train Epoch: 40 [1000/8000 (12%)]\tLoss: 0.001653\n",
      "Train Epoch: 40 [1500/8000 (19%)]\tLoss: 0.056871\n",
      "Train Epoch: 40 [2000/8000 (25%)]\tLoss: 0.000299\n",
      "Train Epoch: 40 [2500/8000 (31%)]\tLoss: 0.000082\n",
      "Train Epoch: 40 [3000/8000 (38%)]\tLoss: 0.001519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [3500/8000 (44%)]\tLoss: 0.004358\n",
      "Train Epoch: 40 [4000/8000 (50%)]\tLoss: 0.000017\n",
      "Train Epoch: 40 [4500/8000 (56%)]\tLoss: 0.000316\n",
      "Train Epoch: 40 [5000/8000 (62%)]\tLoss: 0.002856\n",
      "Train Epoch: 40 [5500/8000 (69%)]\tLoss: 0.038579\n",
      "Train Epoch: 40 [6000/8000 (75%)]\tLoss: 0.000300\n",
      "Train Epoch: 40 [6500/8000 (81%)]\tLoss: 0.011406\n",
      "Train Epoch: 40 [7000/8000 (88%)]\tLoss: 0.016843\n",
      "Train Epoch: 40 [7500/8000 (94%)]\tLoss: 0.000058\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 1990/2000 (100%)\n",
      "\n",
      "Train Epoch: 41 [0/8000 (0%)]\tLoss: 0.019879\n",
      "Train Epoch: 41 [500/8000 (6%)]\tLoss: 0.006420\n",
      "Train Epoch: 41 [1000/8000 (12%)]\tLoss: 0.033746\n",
      "Train Epoch: 41 [1500/8000 (19%)]\tLoss: 0.000176\n",
      "Train Epoch: 41 [2000/8000 (25%)]\tLoss: 0.000059\n",
      "Train Epoch: 41 [2500/8000 (31%)]\tLoss: 0.001773\n",
      "Train Epoch: 41 [3000/8000 (38%)]\tLoss: 0.000031\n",
      "Train Epoch: 41 [3500/8000 (44%)]\tLoss: 0.013740\n",
      "Train Epoch: 41 [4000/8000 (50%)]\tLoss: 0.000071\n",
      "Train Epoch: 41 [4500/8000 (56%)]\tLoss: 0.063386\n",
      "Train Epoch: 41 [5000/8000 (62%)]\tLoss: 0.000246\n",
      "Train Epoch: 41 [5500/8000 (69%)]\tLoss: 0.083215\n",
      "Train Epoch: 41 [6000/8000 (75%)]\tLoss: 0.011169\n",
      "Train Epoch: 41 [6500/8000 (81%)]\tLoss: 0.021793\n",
      "Train Epoch: 41 [7000/8000 (88%)]\tLoss: 0.002440\n",
      "Train Epoch: 41 [7500/8000 (94%)]\tLoss: 0.000228\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 1995/2000 (100%)\n",
      "\n",
      "Train Epoch: 42 [0/8000 (0%)]\tLoss: 0.001725\n",
      "Train Epoch: 42 [500/8000 (6%)]\tLoss: 0.001871\n",
      "Train Epoch: 42 [1000/8000 (12%)]\tLoss: 0.008314\n",
      "Train Epoch: 42 [1500/8000 (19%)]\tLoss: 0.040883\n",
      "Train Epoch: 42 [2000/8000 (25%)]\tLoss: 0.000206\n",
      "Train Epoch: 42 [2500/8000 (31%)]\tLoss: 0.006034\n",
      "Train Epoch: 42 [3000/8000 (38%)]\tLoss: 0.003676\n",
      "Train Epoch: 42 [3500/8000 (44%)]\tLoss: 0.002484\n",
      "Train Epoch: 42 [4000/8000 (50%)]\tLoss: 0.000872\n",
      "Train Epoch: 42 [4500/8000 (56%)]\tLoss: 0.000221\n",
      "Train Epoch: 42 [5000/8000 (62%)]\tLoss: 0.003757\n",
      "Train Epoch: 42 [5500/8000 (69%)]\tLoss: 0.065645\n",
      "Train Epoch: 42 [6000/8000 (75%)]\tLoss: 0.000028\n",
      "Train Epoch: 42 [6500/8000 (81%)]\tLoss: 0.006231\n",
      "Train Epoch: 42 [7000/8000 (88%)]\tLoss: 0.000169\n",
      "Train Epoch: 42 [7500/8000 (94%)]\tLoss: 0.000119\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1984/2000 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/8000 (0%)]\tLoss: 0.000047\n",
      "Train Epoch: 43 [500/8000 (6%)]\tLoss: 0.041707\n",
      "Train Epoch: 43 [1000/8000 (12%)]\tLoss: 0.000088\n",
      "Train Epoch: 43 [1500/8000 (19%)]\tLoss: 0.000084\n",
      "Train Epoch: 43 [2000/8000 (25%)]\tLoss: 0.007961\n",
      "Train Epoch: 43 [2500/8000 (31%)]\tLoss: 0.005226\n",
      "Train Epoch: 43 [3000/8000 (38%)]\tLoss: 0.000063\n",
      "Train Epoch: 43 [3500/8000 (44%)]\tLoss: 0.000242\n",
      "Train Epoch: 43 [4000/8000 (50%)]\tLoss: 0.000120\n",
      "Train Epoch: 43 [4500/8000 (56%)]\tLoss: 0.001818\n",
      "Train Epoch: 43 [5000/8000 (62%)]\tLoss: 0.000189\n",
      "Train Epoch: 43 [5500/8000 (69%)]\tLoss: 0.000081\n",
      "Train Epoch: 43 [6000/8000 (75%)]\tLoss: 0.000110\n",
      "Train Epoch: 43 [6500/8000 (81%)]\tLoss: 0.000092\n",
      "Train Epoch: 43 [7000/8000 (88%)]\tLoss: 0.000339\n",
      "Train Epoch: 43 [7500/8000 (94%)]\tLoss: 0.000205\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 44 [0/8000 (0%)]\tLoss: 0.000112\n",
      "Train Epoch: 44 [500/8000 (6%)]\tLoss: 0.051807\n",
      "Train Epoch: 44 [1000/8000 (12%)]\tLoss: 0.000584\n",
      "Train Epoch: 44 [1500/8000 (19%)]\tLoss: 0.000204\n",
      "Train Epoch: 44 [2000/8000 (25%)]\tLoss: 0.004616\n",
      "Train Epoch: 44 [2500/8000 (31%)]\tLoss: 0.056090\n",
      "Train Epoch: 44 [3000/8000 (38%)]\tLoss: 0.000199\n",
      "Train Epoch: 44 [3500/8000 (44%)]\tLoss: 0.000037\n",
      "Train Epoch: 44 [4000/8000 (50%)]\tLoss: 0.002671\n",
      "Train Epoch: 44 [4500/8000 (56%)]\tLoss: 0.000316\n",
      "Train Epoch: 44 [5000/8000 (62%)]\tLoss: 0.047084\n",
      "Train Epoch: 44 [5500/8000 (69%)]\tLoss: 0.001881\n",
      "Train Epoch: 44 [6000/8000 (75%)]\tLoss: 0.011776\n",
      "Train Epoch: 44 [6500/8000 (81%)]\tLoss: 0.000052\n",
      "Train Epoch: 44 [7000/8000 (88%)]\tLoss: 0.000264\n",
      "Train Epoch: 44 [7500/8000 (94%)]\tLoss: 0.000170\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 1989/2000 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/8000 (0%)]\tLoss: 0.001008\n",
      "Train Epoch: 45 [500/8000 (6%)]\tLoss: 0.005144\n",
      "Train Epoch: 45 [1000/8000 (12%)]\tLoss: 0.001933\n",
      "Train Epoch: 45 [1500/8000 (19%)]\tLoss: 0.000077\n",
      "Train Epoch: 45 [2000/8000 (25%)]\tLoss: 0.007483\n",
      "Train Epoch: 45 [2500/8000 (31%)]\tLoss: 0.002564\n",
      "Train Epoch: 45 [3000/8000 (38%)]\tLoss: 0.000147\n",
      "Train Epoch: 45 [3500/8000 (44%)]\tLoss: 0.000037\n",
      "Train Epoch: 45 [4000/8000 (50%)]\tLoss: 0.015617\n",
      "Train Epoch: 45 [4500/8000 (56%)]\tLoss: 0.000029\n",
      "Train Epoch: 45 [5000/8000 (62%)]\tLoss: 0.043281\n",
      "Train Epoch: 45 [5500/8000 (69%)]\tLoss: 0.000077\n",
      "Train Epoch: 45 [6000/8000 (75%)]\tLoss: 0.001552\n",
      "Train Epoch: 45 [6500/8000 (81%)]\tLoss: 0.000204\n",
      "Train Epoch: 45 [7000/8000 (88%)]\tLoss: 0.000081\n",
      "Train Epoch: 45 [7500/8000 (94%)]\tLoss: 0.024722\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/8000 (0%)]\tLoss: 0.000437\n",
      "Train Epoch: 46 [500/8000 (6%)]\tLoss: 0.000475\n",
      "Train Epoch: 46 [1000/8000 (12%)]\tLoss: 0.003811\n",
      "Train Epoch: 46 [1500/8000 (19%)]\tLoss: 0.013248\n",
      "Train Epoch: 46 [2000/8000 (25%)]\tLoss: 0.001529\n",
      "Train Epoch: 46 [2500/8000 (31%)]\tLoss: 0.000969\n",
      "Train Epoch: 46 [3000/8000 (38%)]\tLoss: 0.017756\n",
      "Train Epoch: 46 [3500/8000 (44%)]\tLoss: 0.000028\n",
      "Train Epoch: 46 [4000/8000 (50%)]\tLoss: 0.001121\n",
      "Train Epoch: 46 [4500/8000 (56%)]\tLoss: 0.001157\n",
      "Train Epoch: 46 [5000/8000 (62%)]\tLoss: 0.022808\n",
      "Train Epoch: 46 [5500/8000 (69%)]\tLoss: 0.093302\n",
      "Train Epoch: 46 [6000/8000 (75%)]\tLoss: 0.000932\n",
      "Train Epoch: 46 [6500/8000 (81%)]\tLoss: 0.000033\n",
      "Train Epoch: 46 [7000/8000 (88%)]\tLoss: 0.000431\n",
      "Train Epoch: 46 [7500/8000 (94%)]\tLoss: 0.002228\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 1994/2000 (100%)\n",
      "\n",
      "Train Epoch: 47 [0/8000 (0%)]\tLoss: 0.000393\n",
      "Train Epoch: 47 [500/8000 (6%)]\tLoss: 0.000612\n",
      "Train Epoch: 47 [1000/8000 (12%)]\tLoss: 0.001412\n",
      "Train Epoch: 47 [1500/8000 (19%)]\tLoss: 0.000287\n",
      "Train Epoch: 47 [2000/8000 (25%)]\tLoss: 0.000111\n",
      "Train Epoch: 47 [2500/8000 (31%)]\tLoss: 0.112846\n",
      "Train Epoch: 47 [3000/8000 (38%)]\tLoss: 0.000426\n",
      "Train Epoch: 47 [3500/8000 (44%)]\tLoss: 0.001297\n",
      "Train Epoch: 47 [4000/8000 (50%)]\tLoss: 0.000317\n",
      "Train Epoch: 47 [4500/8000 (56%)]\tLoss: 0.008773\n",
      "Train Epoch: 47 [5000/8000 (62%)]\tLoss: 0.027580\n",
      "Train Epoch: 47 [5500/8000 (69%)]\tLoss: 0.033129\n",
      "Train Epoch: 47 [6000/8000 (75%)]\tLoss: 0.002396\n",
      "Train Epoch: 47 [6500/8000 (81%)]\tLoss: 0.000242\n",
      "Train Epoch: 47 [7000/8000 (88%)]\tLoss: 0.003263\n",
      "Train Epoch: 47 [7500/8000 (94%)]\tLoss: 0.046898\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/8000 (0%)]\tLoss: 0.000323\n",
      "Train Epoch: 48 [500/8000 (6%)]\tLoss: 0.000040\n",
      "Train Epoch: 48 [1000/8000 (12%)]\tLoss: 0.000747\n",
      "Train Epoch: 48 [1500/8000 (19%)]\tLoss: 0.010239\n",
      "Train Epoch: 48 [2000/8000 (25%)]\tLoss: 0.000385\n",
      "Train Epoch: 48 [2500/8000 (31%)]\tLoss: 0.000018\n",
      "Train Epoch: 48 [3000/8000 (38%)]\tLoss: 0.037346\n",
      "Train Epoch: 48 [3500/8000 (44%)]\tLoss: 0.018353\n",
      "Train Epoch: 48 [4000/8000 (50%)]\tLoss: 0.027340\n",
      "Train Epoch: 48 [4500/8000 (56%)]\tLoss: 0.000161\n",
      "Train Epoch: 48 [5000/8000 (62%)]\tLoss: 0.065384\n",
      "Train Epoch: 48 [5500/8000 (69%)]\tLoss: 0.000303\n",
      "Train Epoch: 48 [6000/8000 (75%)]\tLoss: 0.055169\n",
      "Train Epoch: 48 [6500/8000 (81%)]\tLoss: 0.001874\n",
      "Train Epoch: 48 [7000/8000 (88%)]\tLoss: 0.004519\n",
      "Train Epoch: 48 [7500/8000 (94%)]\tLoss: 0.000502\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 49 [0/8000 (0%)]\tLoss: 0.026957\n",
      "Train Epoch: 49 [500/8000 (6%)]\tLoss: 0.001048\n",
      "Train Epoch: 49 [1000/8000 (12%)]\tLoss: 0.001540\n",
      "Train Epoch: 49 [1500/8000 (19%)]\tLoss: 0.008344\n",
      "Train Epoch: 49 [2000/8000 (25%)]\tLoss: 0.001118\n",
      "Train Epoch: 49 [2500/8000 (31%)]\tLoss: 0.000156\n",
      "Train Epoch: 49 [3000/8000 (38%)]\tLoss: 0.006337\n",
      "Train Epoch: 49 [3500/8000 (44%)]\tLoss: 0.000129\n",
      "Train Epoch: 49 [4000/8000 (50%)]\tLoss: 0.002973\n",
      "Train Epoch: 49 [4500/8000 (56%)]\tLoss: 0.001541\n",
      "Train Epoch: 49 [5000/8000 (62%)]\tLoss: 0.056751\n",
      "Train Epoch: 49 [5500/8000 (69%)]\tLoss: 0.000109\n",
      "Train Epoch: 49 [6000/8000 (75%)]\tLoss: 0.000202\n",
      "Train Epoch: 49 [6500/8000 (81%)]\tLoss: 0.000916\n",
      "Train Epoch: 49 [7000/8000 (88%)]\tLoss: 0.000511\n",
      "Train Epoch: 49 [7500/8000 (94%)]\tLoss: 0.015296\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 1990/2000 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/8000 (0%)]\tLoss: 0.000666\n",
      "Train Epoch: 50 [500/8000 (6%)]\tLoss: 0.010847\n",
      "Train Epoch: 50 [1000/8000 (12%)]\tLoss: 0.000245\n",
      "Train Epoch: 50 [1500/8000 (19%)]\tLoss: 0.009229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 50 [2000/8000 (25%)]\tLoss: 0.000206\n",
      "Train Epoch: 50 [2500/8000 (31%)]\tLoss: 0.000492\n",
      "Train Epoch: 50 [3000/8000 (38%)]\tLoss: 0.000458\n",
      "Train Epoch: 50 [3500/8000 (44%)]\tLoss: 0.000017\n",
      "Train Epoch: 50 [4000/8000 (50%)]\tLoss: 0.000349\n",
      "Train Epoch: 50 [4500/8000 (56%)]\tLoss: 0.000014\n",
      "Train Epoch: 50 [5000/8000 (62%)]\tLoss: 0.000836\n",
      "Train Epoch: 50 [5500/8000 (69%)]\tLoss: 0.007506\n",
      "Train Epoch: 50 [6000/8000 (75%)]\tLoss: 0.000055\n",
      "Train Epoch: 50 [6500/8000 (81%)]\tLoss: 0.003017\n",
      "Train Epoch: 50 [7000/8000 (88%)]\tLoss: 0.009955\n",
      "Train Epoch: 50 [7500/8000 (94%)]\tLoss: 0.001710\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 1989/2000 (99%)\n",
      "\n",
      "Train Epoch: 51 [0/8000 (0%)]\tLoss: 0.009621\n",
      "Train Epoch: 51 [500/8000 (6%)]\tLoss: 0.000024\n",
      "Train Epoch: 51 [1000/8000 (12%)]\tLoss: 0.002693\n",
      "Train Epoch: 51 [1500/8000 (19%)]\tLoss: 0.042458\n",
      "Train Epoch: 51 [2000/8000 (25%)]\tLoss: 0.000013\n",
      "Train Epoch: 51 [2500/8000 (31%)]\tLoss: 0.000306\n",
      "Train Epoch: 51 [3000/8000 (38%)]\tLoss: 0.000105\n",
      "Train Epoch: 51 [3500/8000 (44%)]\tLoss: 0.000265\n",
      "Train Epoch: 51 [4000/8000 (50%)]\tLoss: 0.002227\n",
      "Train Epoch: 51 [4500/8000 (56%)]\tLoss: 0.001710\n",
      "Train Epoch: 51 [5000/8000 (62%)]\tLoss: 0.000110\n",
      "Train Epoch: 51 [5500/8000 (69%)]\tLoss: 0.000233\n",
      "Train Epoch: 51 [6000/8000 (75%)]\tLoss: 0.000012\n",
      "Train Epoch: 51 [6500/8000 (81%)]\tLoss: 0.000239\n",
      "Train Epoch: 51 [7000/8000 (88%)]\tLoss: 0.000454\n",
      "Train Epoch: 51 [7500/8000 (94%)]\tLoss: 0.019910\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 1989/2000 (99%)\n",
      "\n",
      "Train Epoch: 52 [0/8000 (0%)]\tLoss: 0.000636\n",
      "Train Epoch: 52 [500/8000 (6%)]\tLoss: 0.016908\n",
      "Train Epoch: 52 [1000/8000 (12%)]\tLoss: 0.000004\n",
      "Train Epoch: 52 [1500/8000 (19%)]\tLoss: 0.000231\n",
      "Train Epoch: 52 [2000/8000 (25%)]\tLoss: 0.001058\n",
      "Train Epoch: 52 [2500/8000 (31%)]\tLoss: 0.000578\n",
      "Train Epoch: 52 [3000/8000 (38%)]\tLoss: 0.001379\n",
      "Train Epoch: 52 [3500/8000 (44%)]\tLoss: 0.000397\n",
      "Train Epoch: 52 [4000/8000 (50%)]\tLoss: 0.012526\n",
      "Train Epoch: 52 [4500/8000 (56%)]\tLoss: 0.000045\n",
      "Train Epoch: 52 [5000/8000 (62%)]\tLoss: 0.003096\n",
      "Train Epoch: 52 [5500/8000 (69%)]\tLoss: 0.007814\n",
      "Train Epoch: 52 [6000/8000 (75%)]\tLoss: 0.023467\n",
      "Train Epoch: 52 [6500/8000 (81%)]\tLoss: 0.000318\n",
      "Train Epoch: 52 [7000/8000 (88%)]\tLoss: 0.001072\n",
      "Train Epoch: 52 [7500/8000 (94%)]\tLoss: 0.000131\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 1994/2000 (100%)\n",
      "\n",
      "Train Epoch: 53 [0/8000 (0%)]\tLoss: 0.000082\n",
      "Train Epoch: 53 [500/8000 (6%)]\tLoss: 0.000919\n",
      "Train Epoch: 53 [1000/8000 (12%)]\tLoss: 0.000121\n",
      "Train Epoch: 53 [1500/8000 (19%)]\tLoss: 0.008586\n",
      "Train Epoch: 53 [2000/8000 (25%)]\tLoss: 0.006827\n",
      "Train Epoch: 53 [2500/8000 (31%)]\tLoss: 0.021764\n",
      "Train Epoch: 53 [3000/8000 (38%)]\tLoss: 0.003819\n",
      "Train Epoch: 53 [3500/8000 (44%)]\tLoss: 0.001538\n",
      "Train Epoch: 53 [4000/8000 (50%)]\tLoss: 0.008268\n",
      "Train Epoch: 53 [4500/8000 (56%)]\tLoss: 0.005344\n",
      "Train Epoch: 53 [5000/8000 (62%)]\tLoss: 0.015507\n",
      "Train Epoch: 53 [5500/8000 (69%)]\tLoss: 0.000115\n",
      "Train Epoch: 53 [6000/8000 (75%)]\tLoss: 0.000380\n",
      "Train Epoch: 53 [6500/8000 (81%)]\tLoss: 0.028597\n",
      "Train Epoch: 53 [7000/8000 (88%)]\tLoss: 0.000343\n",
      "Train Epoch: 53 [7500/8000 (94%)]\tLoss: 0.000126\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 1990/2000 (100%)\n",
      "\n",
      "Train Epoch: 54 [0/8000 (0%)]\tLoss: 0.010251\n",
      "Train Epoch: 54 [500/8000 (6%)]\tLoss: 0.000072\n",
      "Train Epoch: 54 [1000/8000 (12%)]\tLoss: 0.001250\n",
      "Train Epoch: 54 [1500/8000 (19%)]\tLoss: 0.000822\n",
      "Train Epoch: 54 [2000/8000 (25%)]\tLoss: 0.000048\n",
      "Train Epoch: 54 [2500/8000 (31%)]\tLoss: 0.000027\n",
      "Train Epoch: 54 [3000/8000 (38%)]\tLoss: 0.006142\n",
      "Train Epoch: 54 [3500/8000 (44%)]\tLoss: 0.001656\n",
      "Train Epoch: 54 [4000/8000 (50%)]\tLoss: 0.007179\n",
      "Train Epoch: 54 [4500/8000 (56%)]\tLoss: 0.000333\n",
      "Train Epoch: 54 [5000/8000 (62%)]\tLoss: 0.013770\n",
      "Train Epoch: 54 [5500/8000 (69%)]\tLoss: 0.000034\n",
      "Train Epoch: 54 [6000/8000 (75%)]\tLoss: 0.005287\n",
      "Train Epoch: 54 [6500/8000 (81%)]\tLoss: 0.000068\n",
      "Train Epoch: 54 [7000/8000 (88%)]\tLoss: 0.007727\n",
      "Train Epoch: 54 [7500/8000 (94%)]\tLoss: 0.027328\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 1986/2000 (99%)\n",
      "\n",
      "Train Epoch: 55 [0/8000 (0%)]\tLoss: 0.000135\n",
      "Train Epoch: 55 [500/8000 (6%)]\tLoss: 0.000086\n",
      "Train Epoch: 55 [1000/8000 (12%)]\tLoss: 0.001577\n",
      "Train Epoch: 55 [1500/8000 (19%)]\tLoss: 0.000940\n",
      "Train Epoch: 55 [2000/8000 (25%)]\tLoss: 0.007349\n",
      "Train Epoch: 55 [2500/8000 (31%)]\tLoss: 0.000228\n",
      "Train Epoch: 55 [3000/8000 (38%)]\tLoss: 0.001262\n",
      "Train Epoch: 55 [3500/8000 (44%)]\tLoss: 0.002375\n",
      "Train Epoch: 55 [4000/8000 (50%)]\tLoss: 0.001051\n",
      "Train Epoch: 55 [4500/8000 (56%)]\tLoss: 0.000123\n",
      "Train Epoch: 55 [5000/8000 (62%)]\tLoss: 0.007740\n",
      "Train Epoch: 55 [5500/8000 (69%)]\tLoss: 0.002667\n",
      "Train Epoch: 55 [6000/8000 (75%)]\tLoss: 0.003341\n",
      "Train Epoch: 55 [6500/8000 (81%)]\tLoss: 0.000310\n",
      "Train Epoch: 55 [7000/8000 (88%)]\tLoss: 0.000333\n",
      "Train Epoch: 55 [7500/8000 (94%)]\tLoss: 0.000037\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 1984/2000 (99%)\n",
      "\n",
      "Train Epoch: 56 [0/8000 (0%)]\tLoss: 0.000032\n",
      "Train Epoch: 56 [500/8000 (6%)]\tLoss: 0.047110\n",
      "Train Epoch: 56 [1000/8000 (12%)]\tLoss: 0.005165\n",
      "Train Epoch: 56 [1500/8000 (19%)]\tLoss: 0.002986\n",
      "Train Epoch: 56 [2000/8000 (25%)]\tLoss: 0.000170\n",
      "Train Epoch: 56 [2500/8000 (31%)]\tLoss: 0.000599\n",
      "Train Epoch: 56 [3000/8000 (38%)]\tLoss: 0.000158\n",
      "Train Epoch: 56 [3500/8000 (44%)]\tLoss: 0.000046\n",
      "Train Epoch: 56 [4000/8000 (50%)]\tLoss: 0.000049\n",
      "Train Epoch: 56 [4500/8000 (56%)]\tLoss: 0.000799\n",
      "Train Epoch: 56 [5000/8000 (62%)]\tLoss: 0.001943\n",
      "Train Epoch: 56 [5500/8000 (69%)]\tLoss: 0.004888\n",
      "Train Epoch: 56 [6000/8000 (75%)]\tLoss: 0.004022\n",
      "Train Epoch: 56 [6500/8000 (81%)]\tLoss: 0.000078\n",
      "Train Epoch: 56 [7000/8000 (88%)]\tLoss: 0.020213\n",
      "Train Epoch: 56 [7500/8000 (94%)]\tLoss: 0.000012\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 1991/2000 (100%)\n",
      "\n",
      "Train Epoch: 57 [0/8000 (0%)]\tLoss: 0.000037\n",
      "Train Epoch: 57 [500/8000 (6%)]\tLoss: 0.000016\n",
      "Train Epoch: 57 [1000/8000 (12%)]\tLoss: 0.054508\n",
      "Train Epoch: 57 [1500/8000 (19%)]\tLoss: 0.000207\n",
      "Train Epoch: 57 [2000/8000 (25%)]\tLoss: 0.002683\n",
      "Train Epoch: 57 [2500/8000 (31%)]\tLoss: 0.001054\n",
      "Train Epoch: 57 [3000/8000 (38%)]\tLoss: 0.000083\n",
      "Train Epoch: 57 [3500/8000 (44%)]\tLoss: 0.000112\n",
      "Train Epoch: 57 [4000/8000 (50%)]\tLoss: 0.000031\n",
      "Train Epoch: 57 [4500/8000 (56%)]\tLoss: 0.000902\n",
      "Train Epoch: 57 [5000/8000 (62%)]\tLoss: 0.000053\n",
      "Train Epoch: 57 [5500/8000 (69%)]\tLoss: 0.003042\n",
      "Train Epoch: 57 [6000/8000 (75%)]\tLoss: 0.000010\n",
      "Train Epoch: 57 [6500/8000 (81%)]\tLoss: 0.000060\n",
      "Train Epoch: 57 [7000/8000 (88%)]\tLoss: 0.000037\n",
      "Train Epoch: 57 [7500/8000 (94%)]\tLoss: 0.000434\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 1987/2000 (99%)\n",
      "\n",
      "Train Epoch: 58 [0/8000 (0%)]\tLoss: 0.000544\n",
      "Train Epoch: 58 [500/8000 (6%)]\tLoss: 0.000499\n",
      "Train Epoch: 58 [1000/8000 (12%)]\tLoss: 0.000373\n",
      "Train Epoch: 58 [1500/8000 (19%)]\tLoss: 0.000325\n",
      "Train Epoch: 58 [2000/8000 (25%)]\tLoss: 0.000041\n",
      "Train Epoch: 58 [2500/8000 (31%)]\tLoss: 0.006762\n",
      "Train Epoch: 58 [3000/8000 (38%)]\tLoss: 0.008587\n",
      "Train Epoch: 58 [3500/8000 (44%)]\tLoss: 0.000028\n",
      "Train Epoch: 58 [4000/8000 (50%)]\tLoss: 0.000330\n",
      "Train Epoch: 58 [4500/8000 (56%)]\tLoss: 0.000065\n",
      "Train Epoch: 58 [5000/8000 (62%)]\tLoss: 0.000105\n",
      "Train Epoch: 58 [5500/8000 (69%)]\tLoss: 0.001072\n",
      "Train Epoch: 58 [6000/8000 (75%)]\tLoss: 0.000126\n",
      "Train Epoch: 58 [6500/8000 (81%)]\tLoss: 0.019583\n",
      "Train Epoch: 58 [7000/8000 (88%)]\tLoss: 0.004658\n",
      "Train Epoch: 58 [7500/8000 (94%)]\tLoss: 0.009317\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 59 [0/8000 (0%)]\tLoss: 0.000501\n",
      "Train Epoch: 59 [500/8000 (6%)]\tLoss: 0.000954\n",
      "Train Epoch: 59 [1000/8000 (12%)]\tLoss: 0.008996\n",
      "Train Epoch: 59 [1500/8000 (19%)]\tLoss: 0.000017\n",
      "Train Epoch: 59 [2000/8000 (25%)]\tLoss: 0.000204\n",
      "Train Epoch: 59 [2500/8000 (31%)]\tLoss: 0.001506\n",
      "Train Epoch: 59 [3000/8000 (38%)]\tLoss: 0.000035\n",
      "Train Epoch: 59 [3500/8000 (44%)]\tLoss: 0.026368\n",
      "Train Epoch: 59 [4000/8000 (50%)]\tLoss: 0.003496\n",
      "Train Epoch: 59 [4500/8000 (56%)]\tLoss: 0.000094\n",
      "Train Epoch: 59 [5000/8000 (62%)]\tLoss: 0.001997\n",
      "Train Epoch: 59 [5500/8000 (69%)]\tLoss: 0.015789\n",
      "Train Epoch: 59 [6000/8000 (75%)]\tLoss: 0.000065\n",
      "Train Epoch: 59 [6500/8000 (81%)]\tLoss: 0.029315\n",
      "Train Epoch: 59 [7000/8000 (88%)]\tLoss: 0.000083\n",
      "Train Epoch: 59 [7500/8000 (94%)]\tLoss: 0.000038\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 1988/2000 (99%)\n",
      "\n",
      "Train Epoch: 60 [0/8000 (0%)]\tLoss: 0.000937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [500/8000 (6%)]\tLoss: 0.000024\n",
      "Train Epoch: 60 [1000/8000 (12%)]\tLoss: 0.000063\n",
      "Train Epoch: 60 [1500/8000 (19%)]\tLoss: 0.000038\n",
      "Train Epoch: 60 [2000/8000 (25%)]\tLoss: 0.000018\n",
      "Train Epoch: 60 [2500/8000 (31%)]\tLoss: 0.026290\n",
      "Train Epoch: 60 [3000/8000 (38%)]\tLoss: 0.000027\n",
      "Train Epoch: 60 [3500/8000 (44%)]\tLoss: 0.000891\n",
      "Train Epoch: 60 [4000/8000 (50%)]\tLoss: 0.002646\n",
      "Train Epoch: 60 [4500/8000 (56%)]\tLoss: 0.000266\n",
      "Train Epoch: 60 [5000/8000 (62%)]\tLoss: 0.008454\n",
      "Train Epoch: 60 [5500/8000 (69%)]\tLoss: 0.015476\n",
      "Train Epoch: 60 [6000/8000 (75%)]\tLoss: 0.000244\n",
      "Train Epoch: 60 [6500/8000 (81%)]\tLoss: 0.008485\n",
      "Train Epoch: 60 [7000/8000 (88%)]\tLoss: 0.006309\n",
      "Train Epoch: 60 [7500/8000 (94%)]\tLoss: 0.000306\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 1986/2000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Epochs:\", epochs)\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
