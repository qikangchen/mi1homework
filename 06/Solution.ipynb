{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a14be816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "925d2bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 60000 Test size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 19:07:03.395101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-04 19:07:03.395120: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-04 19:07:03.395133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kang-arch): /proc/driver/nvidia/version does not exist\n",
      "2022-12-04 19:07:03.395347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    y_train = tf.one_hot(y_train, 10)\n",
    "    y_test = tf.one_hot(y_test, 10)\n",
    "    \n",
    "    print(\n",
    "        f'Training size: {len(x_train)}',\n",
    "        f'Test size: {len(x_test)}'\n",
    "    )\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000, reshuffle_each_iteration=True).batch(100)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(100)\n",
    "    return train_ds, test_ds\n",
    "\n",
    "train_ds, test_ds = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dafe075",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 1500)              1177500   \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 1500)              2251500   \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 1500)              2251500   \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                15010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,695,510\n",
      "Trainable params: 5,695,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "    def summary(self, input_shape=(28,28)):\n",
    "        x = layers.Input(shape=input_shape)\n",
    "        model = tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
    "        print(model.summary())\n",
    "    \n",
    "    def default_kernel_initializer(self):\n",
    "        return keras.initializers.TruncatedNormal(\n",
    "            mean=0.0,\n",
    "            stddev=0.01,\n",
    "            seed=1000\n",
    "        )\n",
    "    \n",
    "    def default_bias_initializer(self):\n",
    "         return keras.initializers.Constant(-0.1)\n",
    "        \n",
    "    def create_dense_layer(self, neuron_amount, activation, name):\n",
    "        return layers.Dense(\n",
    "            neuron_amount,\n",
    "            activation=activation,\n",
    "#             kernel_initializer=self.default_kernel_initializer(),\n",
    "#             bias_initializer=self.default_bias_initializer(),\n",
    "            name=name)\n",
    "    \n",
    "class LinearModel(MyModel):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.flatten = layers.Flatten(input_shape=(28,28), name='flatten')\n",
    "        self.o = layers.Dense(10, activation='softmax', name='output')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.o(x)\n",
    "        return x\n",
    "    \n",
    "class MlpModel(MyModel):\n",
    "    def __init__(self):\n",
    "        super(MlpModel, self).__init__()\n",
    "        \n",
    "        self.flatten = layers.Flatten(input_shape=(28,28), name='flatten')\n",
    "        self.h1 = self.create_dense_layer(1500, 'relu', 'hidden_1')\n",
    "        self.h2 = self.create_dense_layer(1500, 'relu', 'hidden_2')\n",
    "        self.h3 = self.create_dense_layer(1500, 'relu', 'hidden_3')\n",
    "        self.o = self.create_dense_layer(10, 'softmax', 'output')\n",
    "     \n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.h1(x)\n",
    "        x = self.h2(x)\n",
    "        x = self.h3(x)\n",
    "        x = self.o(x)\n",
    "        return x\n",
    "    \n",
    "class MlpDropoutModel(MyModel):\n",
    "    def __init__(self):\n",
    "        super(MlpDropoutModel, self).__init__()\n",
    "        \n",
    "        self.flatten = layers.Flatten(input_shape=(28,28), name='flatten')\n",
    "        self.h1 = self.create_dense_layer(1500, 'relu', 'hidden_1')\n",
    "        self.h2 = self.create_dense_layer(1500, 'relu', 'hidden_2')\n",
    "        self.h3 = self.create_dense_layer(1500, 'relu', 'hidden_3')\n",
    "        self.o = self.create_dense_layer(10, 'softmax', 'output')\n",
    "        \n",
    "        dropout_rate = 0.5\n",
    "        self.dropout_layer1 = layers.Dropout(rate=dropout_rate, name='dropout_1')\n",
    "        self.dropout_layer2 = layers.Dropout(rate=dropout_rate, name='dropout_2')\n",
    "        self.dropout_layer3 = layers.Dropout(rate=dropout_rate, name='dropout_3')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.h1(x)\n",
    "        x = self.dropout_layer1(x)\n",
    "        x = self.h2(x)\n",
    "        x = self.dropout_layer2(x)\n",
    "        x = self.h3(x)\n",
    "        x = self.dropout_layer3(x)\n",
    "        x = self.o(x)\n",
    "        return x\n",
    "\n",
    "class ConvModel(MyModel):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.re = layers.Reshape((28,28,1), name='add_channel')\n",
    "        \n",
    "        self.conv1 = self.create_conv_2D_layer(32, 'conv1')\n",
    "        self.maxp1 = self.create_max_pooling_layer('maxp1')\n",
    "        self.conv2 = self.create_conv_2D_layer(64, 'conv2')\n",
    "        self.maxp2 = self.create_max_pooling_layer('maxp2')\n",
    "        \n",
    "        self.f = layers.Flatten()\n",
    "        self.o = self.create_dense_layer(10, 'softmax', 'output')\n",
    "        \n",
    "    def create_conv_2D_layer(self, filter_amount, name):\n",
    "        return layers.Conv2D(\n",
    "            filters=filter_amount,\n",
    "            kernel_size=(5,5), \n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            strides=(1,1),\n",
    "#             kernel_initializer=self.default_kernel_initializer(),\n",
    "#             bias_initializer=self.default_bias_initializer(),\n",
    "            name=name\n",
    "        )\n",
    "    \n",
    "    def create_max_pooling_layer(self, name):\n",
    "        return layers.MaxPooling2D(\n",
    "            pool_size=(2,2),\n",
    "            name=name\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = self.re(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxp2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.o(x)\n",
    "    \n",
    "        return x\n",
    "   \n",
    "    \n",
    "model = MlpModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26af3da",
   "metadata": {},
   "source": [
    "Note: It is possible to bake the tf.nn.softmax function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output.\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da630e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.loss_object = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        self.train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "        \n",
    "        self.test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "        self.test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, model, optimizer, x, yt):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x, training=True)\n",
    "            loss = self.loss_object(yt, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        self.train_loss(loss)\n",
    "        self.train_accuracy(yt, predictions)\n",
    "        \n",
    "    @tf.function\n",
    "    def test_step(self, model, x, yt):\n",
    "        predictions = model(x, training=False)\n",
    "        loss = self.loss_object(yt, predictions)\n",
    "        \n",
    "        self.test_loss(loss)\n",
    "        self.test_accuracy(yt, predictions)\n",
    "    \n",
    "    def train(self, train_ds, model, name, epochs):\n",
    "        \n",
    "        train_summary_writer, test_summary_writer = self.create_summary_writer(name)\n",
    "        \n",
    "        i = 0\n",
    "        for epoch in range(epochs):\n",
    "            for x, yt in train_ds:\n",
    "                if(i%100 == 0):\n",
    "                    self.reset_states()\n",
    "#                     print(f'Iteration {i//100}')\n",
    "                    self.train_step(model, self.optimizer, x, yt)\n",
    "\n",
    "                    for x, yt in test_ds:\n",
    "                        self.test_step(model, x, yt)\n",
    "\n",
    "                    with train_summary_writer.as_default():\n",
    "                        tf.summary.scalar('accuracy:', self.train_accuracy.result(), step=i//100) \n",
    "\n",
    "                    with test_summary_writer.as_default():\n",
    "                        tf.summary.scalar('accuracy:', self.test_accuracy.result(), step=i//100) \n",
    "            \n",
    "                i += 1\n",
    "                \n",
    "            \n",
    "            print(\n",
    "                f'Epoch {epoch + 1}',\n",
    "#                 f'Loss: {self.train_loss.result()}',\n",
    "                f'Accuracy: {self.train_accuracy.result()}',\n",
    "#                 f'Test Loss: {self.test_loss.result()}',\n",
    "                f'Test Accuracy: {self.test_accuracy.result()}',\n",
    "            )\n",
    "        \n",
    "    def create_summary_writer(self, name):\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        train_log_dir = 'logs/' + name + '/' + current_time + '/train'\n",
    "        test_log_dir = 'logs/' + name + '/' + current_time + '/test'\n",
    "        train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "        test_summary_writer = tf.summary.create_file_writer(test_log_dir) \n",
    "        \n",
    "        return train_summary_writer, test_summary_writer\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.train_loss.reset_states()\n",
    "        self.train_accuracy.reset_state()\n",
    "        self.test_loss.reset_states()\n",
    "        self.test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfe09a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Accuracy: 0.8399999737739563 Test Accuracy: 0.7199000120162964\n",
      "Epoch 2 Accuracy: 0.7799999713897705 Test Accuracy: 0.8111000061035156\n",
      "Epoch 3 Accuracy: 0.949999988079071 Test Accuracy: 0.8580999970436096\n",
      "Epoch 4 Accuracy: 0.8199999928474426 Test Accuracy: 0.8661999702453613\n",
      "Epoch 5 Accuracy: 0.8600000143051147 Test Accuracy: 0.8860999941825867\n",
      "Epoch 6 Accuracy: 0.9399999976158142 Test Accuracy: 0.909600019454956\n",
      "Epoch 7 Accuracy: 0.8899999856948853 Test Accuracy: 0.9010000228881836\n",
      "Epoch 8 Accuracy: 0.9100000262260437 Test Accuracy: 0.9186999797821045\n",
      "Epoch 9 Accuracy: 0.9399999976158142 Test Accuracy: 0.9128000140190125\n",
      "Epoch 10 Accuracy: 0.949999988079071 Test Accuracy: 0.9301000237464905\n",
      "Epoch 11 Accuracy: 0.9300000071525574 Test Accuracy: 0.9254999756813049\n",
      "Epoch 12 Accuracy: 0.9200000166893005 Test Accuracy: 0.9287999868392944\n",
      "Epoch 13 Accuracy: 0.8899999856948853 Test Accuracy: 0.9369999766349792\n",
      "Epoch 14 Accuracy: 0.9399999976158142 Test Accuracy: 0.9340000152587891\n",
      "Epoch 15 Accuracy: 0.9100000262260437 Test Accuracy: 0.9469000101089478\n",
      "Epoch 16 Accuracy: 0.9200000166893005 Test Accuracy: 0.9370999932289124\n",
      "Epoch 17 Accuracy: 0.949999988079071 Test Accuracy: 0.935699999332428\n",
      "Epoch 18 Accuracy: 0.9700000286102295 Test Accuracy: 0.9463000297546387\n",
      "Epoch 19 Accuracy: 0.9800000190734863 Test Accuracy: 0.9384999871253967\n",
      "Epoch 20 Accuracy: 0.949999988079071 Test Accuracy: 0.9412999749183655\n",
      "Epoch 21 Accuracy: 0.9399999976158142 Test Accuracy: 0.9455999732017517\n",
      "Epoch 22 Accuracy: 0.9200000166893005 Test Accuracy: 0.9424999952316284\n",
      "Epoch 23 Accuracy: 0.9200000166893005 Test Accuracy: 0.9302999973297119\n",
      "Epoch 24 Accuracy: 0.9300000071525574 Test Accuracy: 0.9375\n",
      "Epoch 25 Accuracy: 0.9300000071525574 Test Accuracy: 0.9402999877929688\n",
      "Epoch 26 Accuracy: 0.9399999976158142 Test Accuracy: 0.9381999969482422\n",
      "Epoch 27 Accuracy: 0.949999988079071 Test Accuracy: 0.9510999917984009\n",
      "Epoch 28 Accuracy: 0.9599999785423279 Test Accuracy: 0.9498999714851379\n",
      "Epoch 29 Accuracy: 0.9300000071525574 Test Accuracy: 0.9491000175476074\n",
      "Epoch 30 Accuracy: 0.9800000190734863 Test Accuracy: 0.9441999793052673\n",
      "Epoch 31 Accuracy: 0.949999988079071 Test Accuracy: 0.9470999836921692\n",
      "Epoch 32 Accuracy: 0.9599999785423279 Test Accuracy: 0.944599986076355\n",
      "Epoch 1 Accuracy: 0.4300000071525574 Test Accuracy: 0.6521000266075134\n",
      "Epoch 2 Accuracy: 0.6200000047683716 Test Accuracy: 0.8251000046730042\n",
      "Epoch 3 Accuracy: 0.75 Test Accuracy: 0.7961999773979187\n",
      "Epoch 4 Accuracy: 0.7900000214576721 Test Accuracy: 0.8553000092506409\n",
      "Epoch 5 Accuracy: 0.8700000047683716 Test Accuracy: 0.881600022315979\n",
      "Epoch 6 Accuracy: 0.8500000238418579 Test Accuracy: 0.8949000239372253\n",
      "Epoch 7 Accuracy: 0.8199999928474426 Test Accuracy: 0.8765000104904175\n",
      "Epoch 8 Accuracy: 0.8700000047683716 Test Accuracy: 0.9064000248908997\n",
      "Epoch 9 Accuracy: 0.9300000071525574 Test Accuracy: 0.904699981212616\n",
      "Epoch 10 Accuracy: 0.9399999976158142 Test Accuracy: 0.8955000042915344\n",
      "Epoch 11 Accuracy: 0.8299999833106995 Test Accuracy: 0.9132999777793884\n",
      "Epoch 12 Accuracy: 0.8199999928474426 Test Accuracy: 0.9176999926567078\n",
      "Epoch 13 Accuracy: 0.8799999952316284 Test Accuracy: 0.9273999929428101\n",
      "Epoch 14 Accuracy: 0.9200000166893005 Test Accuracy: 0.9300000071525574\n",
      "Epoch 15 Accuracy: 0.8999999761581421 Test Accuracy: 0.9266999959945679\n",
      "Epoch 16 Accuracy: 0.8600000143051147 Test Accuracy: 0.9251999855041504\n",
      "Epoch 17 Accuracy: 0.8999999761581421 Test Accuracy: 0.9247999787330627\n",
      "Epoch 18 Accuracy: 0.9300000071525574 Test Accuracy: 0.9326000213623047\n",
      "Epoch 19 Accuracy: 0.9100000262260437 Test Accuracy: 0.9205999970436096\n",
      "Epoch 20 Accuracy: 0.9200000166893005 Test Accuracy: 0.9294000267982483\n",
      "Epoch 21 Accuracy: 0.8899999856948853 Test Accuracy: 0.9277999997138977\n",
      "Epoch 22 Accuracy: 0.8700000047683716 Test Accuracy: 0.9334999918937683\n",
      "Epoch 23 Accuracy: 0.9599999785423279 Test Accuracy: 0.9369000196456909\n",
      "Epoch 24 Accuracy: 0.9100000262260437 Test Accuracy: 0.9391000270843506\n",
      "Epoch 25 Accuracy: 0.9100000262260437 Test Accuracy: 0.9404000043869019\n",
      "Epoch 26 Accuracy: 0.9200000166893005 Test Accuracy: 0.9348999857902527\n",
      "Epoch 27 Accuracy: 0.9399999976158142 Test Accuracy: 0.9370999932289124\n",
      "Epoch 28 Accuracy: 0.949999988079071 Test Accuracy: 0.9420999884605408\n",
      "Epoch 29 Accuracy: 0.9399999976158142 Test Accuracy: 0.9463000297546387\n",
      "Epoch 30 Accuracy: 0.9200000166893005 Test Accuracy: 0.9368000030517578\n",
      "Epoch 31 Accuracy: 0.9200000166893005 Test Accuracy: 0.9359999895095825\n",
      "Epoch 32 Accuracy: 0.9599999785423279 Test Accuracy: 0.9416999816894531\n",
      "Epoch 1 Accuracy: 0.5 Test Accuracy: 0.4081000089645386\n",
      "Epoch 2 Accuracy: 0.7699999809265137 Test Accuracy: 0.6840000152587891\n",
      "Epoch 3 Accuracy: 0.7699999809265137 Test Accuracy: 0.713100016117096\n",
      "Epoch 4 Accuracy: 0.7599999904632568 Test Accuracy: 0.7957000136375427\n",
      "Epoch 5 Accuracy: 0.7699999809265137 Test Accuracy: 0.8586000204086304\n",
      "Epoch 6 Accuracy: 0.8700000047683716 Test Accuracy: 0.8776999711990356\n",
      "Epoch 7 Accuracy: 0.8500000238418579 Test Accuracy: 0.8981999754905701\n",
      "Epoch 8 Accuracy: 0.9399999976158142 Test Accuracy: 0.9082000255584717\n",
      "Epoch 9 Accuracy: 0.949999988079071 Test Accuracy: 0.9043999910354614\n",
      "Epoch 10 Accuracy: 0.9399999976158142 Test Accuracy: 0.9169999957084656\n",
      "Epoch 11 Accuracy: 0.9100000262260437 Test Accuracy: 0.9225999712944031\n",
      "Epoch 12 Accuracy: 0.8899999856948853 Test Accuracy: 0.9293000102043152\n",
      "Epoch 13 Accuracy: 0.9100000262260437 Test Accuracy: 0.9297000169754028\n",
      "Epoch 14 Accuracy: 0.9399999976158142 Test Accuracy: 0.9180999994277954\n",
      "Epoch 15 Accuracy: 0.9700000286102295 Test Accuracy: 0.9362000226974487\n",
      "Epoch 16 Accuracy: 0.949999988079071 Test Accuracy: 0.942300021648407\n",
      "Epoch 17 Accuracy: 0.9599999785423279 Test Accuracy: 0.9401000142097473\n",
      "Epoch 18 Accuracy: 0.9200000166893005 Test Accuracy: 0.9430000185966492\n",
      "Epoch 19 Accuracy: 0.9599999785423279 Test Accuracy: 0.9544000029563904\n",
      "Epoch 20 Accuracy: 0.9399999976158142 Test Accuracy: 0.9509999752044678\n",
      "Epoch 21 Accuracy: 0.9700000286102295 Test Accuracy: 0.9483000040054321\n",
      "Epoch 22 Accuracy: 0.9900000095367432 Test Accuracy: 0.9531000256538391\n",
      "Epoch 23 Accuracy: 0.9399999976158142 Test Accuracy: 0.9480999708175659\n",
      "Epoch 24 Accuracy: 0.9700000286102295 Test Accuracy: 0.9562000036239624\n",
      "Epoch 25 Accuracy: 0.9399999976158142 Test Accuracy: 0.9559999704360962\n",
      "Epoch 26 Accuracy: 0.9700000286102295 Test Accuracy: 0.9539999961853027\n",
      "Epoch 27 Accuracy: 0.9700000286102295 Test Accuracy: 0.963100016117096\n",
      "Epoch 28 Accuracy: 0.9800000190734863 Test Accuracy: 0.9638000130653381\n",
      "Epoch 29 Accuracy: 0.9900000095367432 Test Accuracy: 0.9645000100135803\n",
      "Epoch 30 Accuracy: 0.9800000190734863 Test Accuracy: 0.9623000025749207\n",
      "Epoch 31 Accuracy: 0.9900000095367432 Test Accuracy: 0.9667999744415283\n",
      "Epoch 32 Accuracy: 0.9599999785423279 Test Accuracy: 0.9682000279426575\n"
     ]
    }
   ],
   "source": [
    "class Result():\n",
    "    \n",
    "    def linear_model(self):\n",
    "        model = LinearModel()\n",
    "        \n",
    "        optimizer = tf.optimizers.experimental.SGD(0.5)\n",
    "        trainer = Trainer(optimizer)\n",
    "    \n",
    "        # 16 epchos = 10000 iteration\n",
    "        trainer.train(train_ds, model, 'linear_model', 16)\n",
    "    \n",
    "    def mlp_model(self):\n",
    "        model = MlpModel() \n",
    "        \n",
    "        optimizer = tf.optimizers.Adam(\n",
    "            learning_rate=0.001,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-08\n",
    "        )\n",
    "        trainer = Trainer(optimizer)\n",
    "        \n",
    "        trainer.train(train_ds, model, 'mlp_model', 32)\n",
    "        \n",
    "    def mlpdropout_model(self):\n",
    "        model = MlpDropoutModel() \n",
    "        \n",
    "        optimizer = tf.optimizers.Adam(\n",
    "            learning_rate=0.001,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-08\n",
    "        )\n",
    "        trainer = Trainer(optimizer)\n",
    "        trainer.train(train_ds, model, 'mlp_dropout_model', 32)\n",
    "        \n",
    "    def conv_model(self):\n",
    "        model = ConvModel() \n",
    "        \n",
    "        optimizer = tf.optimizers.Adam(\n",
    "            learning_rate=0.001,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "            epsilon=1e-08\n",
    "        )\n",
    "        trainer = Trainer(optimizer)\n",
    "        trainer.train(train_ds, model, 'conv_model', 32)\n",
    "    \n",
    "result = Result()\n",
    "result.linear_model()\n",
    "result.mlp_model()\n",
    "result.mlpdropout_model()\n",
    "result.conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0eb56b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 153067), started 0:14:05 ago. (Use '!kill 153067' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9d54a6be809e1e4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9d54a6be809e1e4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
