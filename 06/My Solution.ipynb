{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8825401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "230f52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    y_train = tf.one_hot(y_train, 10)\n",
    "    y_test = tf.one_hot(y_test, 10)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000, reshuffle_each_iteration=True).batch(100)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(10000).batch(100)\n",
    "    return train_ds, test_ds\n",
    "\n",
    "train_ds, test_ds = get_data()\n",
    "\n",
    "batch1 = train_ds.as_numpy_iterator().next()\n",
    "batch1x = batch1[0]\n",
    "batch1y = batch1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1ee07539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_16 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28,28)),\n",
    "        layers.Dense(10, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ad222d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4bcbceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (logit):  [[ 2.02 -5.52 -3.43  1.07 -4.75 11.27 -1.85 -2.92  6.94  2.36]]\n",
      "Prediction (softmax):  [[0.   0.   0.   0.   0.   0.99 0.   0.   0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# prediction example\n",
    "prediction = model(batch1x[:1]) \n",
    "prediction_softmax = tf.nn.softmax(prediction)\n",
    "print('Prediction (logit): ', np.round(prediction.numpy(), 2))\n",
    "print('Prediction (softmax): ', np.round(prediction_softmax.numpy(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "63cd5804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0133690825\n"
     ]
    }
   ],
   "source": [
    "# define loss object\n",
    "loss_object = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss = loss_object(batch1y[:1], prediction)\n",
    "\n",
    "print(\"Loss: \", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fceed087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0133690825\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# define loss and accuracy metric for displaying for human user \n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "print(\"Loss: \", train_loss(loss).numpy())\n",
    "print(\"Accuracy: \", train_accuracy(batch1y[0], prediction).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265713e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "241bff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3093 - accuracy: 0.9047\n",
      "Epoch 2/3\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1504 - accuracy: 0.9553\n",
      "Epoch 3/3\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1196 - accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92342be230>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.experimental.SGD(learning_rate=0.5)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(train_ds, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
